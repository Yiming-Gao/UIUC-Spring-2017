{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not using the `Assignments` tab on the course JupyterHub server to read this notebook, read [Activating the assignments tab](https://github.com/lcdm-uiuc/info490-sp17/blob/master/help/act_assign_tab.md).\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_ â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7.2. Text Classification.\n",
    "\n",
    "In this problem, we perform text classificatoin tasks by using the scikit learn machine learning libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import re\n",
    "import requests\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "from nose.tools import (\n",
    "    assert_equal,\n",
    "    assert_is_instance,\n",
    "    assert_almost_equal,\n",
    "    assert_true\n",
    ")\n",
    "from numpy.testing import assert_array_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a data set borrowed from [here](https://github.com/jacoxu/StackOverflow) that has been made available by Kaggle. It contains 20,000 instances of StackOverFlow post titles accompanied by labels in a separate file. For the purposes of this assignment, I have combined them in one file.\n",
    "Firstly, we load the contents of the file into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linq</td>\n",
       "      <td>How do I fill a DataSet or a DataTable from a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linq</td>\n",
       "      <td>How do you page a collection with LINQ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>svn</td>\n",
       "      <td>Best Subversion clients for Windows Vista (64bit)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svn</td>\n",
       "      <td>Best Practice: Collaborative Environment, Bin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>visual-studio</td>\n",
       "      <td>Visual Studio Setup Project - Per User Registr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Label                                               Text\n",
       "0           linq  How do I fill a DataSet or a DataTable from a ...\n",
       "1           linq            How do you page a collection with LINQ?\n",
       "2            svn  Best Subversion clients for Windows Vista (64bit)\n",
       "3            svn  Best Practice: Collaborative Environment, Bin ...\n",
       "4  visual-studio  Visual Studio Setup Project - Per User Registr..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/home/data_scientist/data/misc/combined_StackOverFlow.txt\"\n",
    "sof_df = pd.read_table(file_path, header=None, names=[\"Label\",\"Text\"])\n",
    "sof_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data set for training and testing\n",
    "\n",
    "We shall be making use of [StratifiedShuffleSplit](http://scikit-learn.org/0.17/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html) to split the data set into train and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "91937775e26e603b9fe809e1ebfa6102",
     "grade": false,
     "grade_id": "split_ans",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size, random_state):\n",
    "    '''\n",
    "    Creates a training set and a test from the data set.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pd.core.series.Series object.\n",
    "    y: pd.core.series.Series object.\n",
    "    fileids: A list of strings.\n",
    "    categories: A list of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 4-tuple (X_train, X_test, y_train, y_test)\n",
    "    All four elements in the tuple are pd.core.series.Series.\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    sss = StratifiedShuffleSplit(y, test_size = test_size, random_state = random_state)\n",
    "    \n",
    "    for train_index, test_index in sss:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "cb1d13424a2e5e0624df0751c8395deb",
     "grade": false,
     "grade_id": "split",
     "locked": true,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(sof_df['Text'], sof_df['Label'], 0.25, check_random_state(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "da71636ba02beed24f29a7e8e74a1127",
     "grade": true,
     "grade_id": "split_test",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(X_train, pd.core.series.Series)\n",
    "assert_is_instance(X_test, pd.core.series.Series)\n",
    "assert_is_instance(y_train, pd.core.series.Series)\n",
    "assert_is_instance(y_test, pd.core.series.Series)\n",
    "\n",
    "assert_true(all(isinstance(elem, str) for elem in X_train))\n",
    "assert_true(all(isinstance(elem, str) for elem in X_test))\n",
    "assert_true(all(isinstance(elem, str) for elem in y_train))\n",
    "assert_true(all(isinstance(elem, str) for elem in y_test))\n",
    "\n",
    "assert_equal(len(X_train), 15000)\n",
    "assert_equal(len(X_test), 5000)\n",
    "assert_equal(len(X_train), len(y_train))\n",
    "assert_equal(len(X_test), len(y_test))\n",
    "\n",
    "assert_equal(X_train[0][:20], 'How do I fill a Data')\n",
    "assert_equal(y_train[0], 'linq')\n",
    "assert_equal(X_test.iloc[0][:20], 'Can MacOS be run in ')\n",
    "assert_equal(y_test.iloc[0], 'osx')\n",
    "\n",
    "assert_equal(X_train[2][:20], 'Best Subversion clie')\n",
    "assert_equal(y_train[2], 'svn')\n",
    "assert_equal(X_test.iloc[2][:20], 'How to format a inpu')\n",
    "assert_equal(y_test.iloc[2], 'matlab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (no pipeline, no stop words)\n",
    "Use `CountVectorizer` to create a document term matrix for the titles, and apply the Logistic Regression algorithm to classify which label the title belongs to. Do not use pipeline (yet). Do not use stop words (yet). Use default parameters for both `CountVectorizer` and `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "511f5d85c6c0e6932909544a97de02f1",
     "grade": false,
     "grade_id": "cv_lr_ans",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def cv_lr(X_train, y_train, X_test, random_state):\n",
    "    '''\n",
    "    Creates a document term matrix and uses LR classifier to make text classifications.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A pd.core.Core. Series object.\n",
    "    y_train: A pd.core.Core. Series object.\n",
    "    X_test: A pd.core.Core. Series object.\n",
    "    random_state: A np.random.RandomState instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (cv, lr, y_pred)\n",
    "    cv: A CountVectorizer instance.\n",
    "    lr: A LogisticRegression instance.\n",
    "    y_pred: A numpy array.\n",
    "    '''\n",
    "    \n",
    "    # create the model\n",
    "    cv = CountVectorizer()\n",
    "    cv.fit(X_train)\n",
    "    train_counts = cv.transform(X_train)\n",
    "    test_data = cv.transform(X_test)\n",
    "    \n",
    "    lr = LogisticRegression(random_state = random_state)\n",
    "    lr.fit(train_counts, y_train)\n",
    "    \n",
    "    # make the prediction\n",
    "    y_pred = lr.predict(test_data)\n",
    "    \n",
    "    return cv, lr, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b2cc991e8d25ffb554724e3e39d764c7",
     "grade": false,
     "grade_id": "cv_lr",
     "locked": true,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR prediction accuracy = 87.1%\n"
     ]
    }
   ],
   "source": [
    "cv1, lr1, y_pred1 = cv_lr(X_train, y_train, X_test, random_state=check_random_state(0))\n",
    "score1 = accuracy_score(y_pred1, y_test)\n",
    "print(\"LR prediction accuracy = {0:3.1f}%\".format(100.0 * score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "1c876fed372ba152a8326a0ce35836e4",
     "grade": true,
     "grade_id": "cv_lr_test",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(cv1, CountVectorizer)\n",
    "assert_is_instance(lr1, LogisticRegression)\n",
    "assert_is_instance(y_pred1, np.ndarray)\n",
    "assert_equal(cv1.stop_words, None)\n",
    "assert_equal(len(y_pred1), len(y_test))\n",
    "assert_array_equal(y_pred1[:5], ['osx', 'ajax', 'matlab', 'qt', 'matlab'])\n",
    "assert_array_equal(y_pred1[-5:], ['haskell', 'svn', 'drupal', 'cocoa', 'scala'])\n",
    "assert_almost_equal(score1, 0.871)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (Pipeline, no stop words)\n",
    "\n",
    "- Build a pipeline by using `CountVectorizer` and `LogisticRegression`. Name the first step `cv` and the second step `lr`. Do not use stop words (yet). Use default parameters for both `CountVectorizer` and `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "fb379893954958ffa8bd3ce8c71d0824",
     "grade": false,
     "grade_id": "cv_lr_pipe_ans",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def cv_lr_pipe(X_train, y_train, X_test, random_state):\n",
    "    \n",
    "    tools = [('cv', CountVectorizer()), ('lr', LogisticRegression(random_state = random_state))]\n",
    "    clf = Pipeline(tools)\n",
    "\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    return clf, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ad1612ed1aeaa7a42e54eeb1f2dd4c78",
     "grade": false,
     "grade_id": "cv_lr_pipe",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR prediction accuracy = 87.1%\n"
     ]
    }
   ],
   "source": [
    "clf2, y_pred2 = cv_lr_pipe(X_train, y_train, X_test, random_state=check_random_state(0))\n",
    "score2 = accuracy_score(y_pred2, y_test)\n",
    "print(\"LR prediction accuracy = {0:3.1f}%\".format(100.0 * score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "cd62acbc09d590061b442c0b65181797",
     "grade": true,
     "grade_id": "cv_lr_pipe_test",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf2, Pipeline)\n",
    "assert_is_instance(y_pred2, np.ndarray)\n",
    "cv2 = clf2.named_steps['cv']\n",
    "assert_is_instance(cv2, CountVectorizer)\n",
    "assert_is_instance(clf2.named_steps['lr'], LogisticRegression)\n",
    "assert_equal(cv2.stop_words, None)\n",
    "assert_equal(len(y_pred2), len(y_test))\n",
    "assert_array_equal(y_pred1, y_pred2)\n",
    "assert_array_equal(y_pred1, y_pred2)\n",
    "assert_almost_equal(score1, score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (Pipeline and stop words)\n",
    "\n",
    "- Build a pipeline by using `CountVectorizer` and `LogisticRegression`. Name the first step `cv` and the second step `lr`. Use English stop words. Use default parameters for both `CountVectorizer` and `LogisticRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "dd019a38eb0f6f9228895840093c82b0",
     "grade": false,
     "grade_id": "cv_lr_pipe_sw_ans",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def cv_lr_pipe_sw(X_train, y_train, X_test, random_state):\n",
    "    '''\n",
    "    Creates a document term matrix and uses LR classifier to make document classifications.\n",
    "    Uses English stop words.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A pd.core.Core. Series object.\n",
    "    y_train: A pd.core.Core. Series object.\n",
    "    X_test: A pd.core.Core. Series object.\n",
    "    random_state: A np.random.RandomState instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (clf, y_pred)\n",
    "    clf: A Pipeline instance.\n",
    "    y_pred: A numpy array.\n",
    "    '''\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    tools = [('cv', CountVectorizer()), ('lr', LogisticRegression(random_state = random_state))]\n",
    "    clf = Pipeline(tools)\n",
    "    \n",
    "    # Note: small e\n",
    "    clf.set_params(cv__stop_words = 'english')\n",
    "\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    \n",
    "    return clf, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2547292ef9ff2d62469298d8062ce790",
     "grade": false,
     "grade_id": "cv_lr_pipe_sw",
     "locked": true,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR prediction accuracy = 87.2%\n"
     ]
    }
   ],
   "source": [
    "clf3, y_pred3 = cv_lr_pipe_sw(X_train, y_train, X_test, random_state=check_random_state(0))\n",
    "score3 = accuracy_score(y_pred3, y_test)\n",
    "print(\"LR prediction accuracy = {0:3.1f}%\".format(100.0 * score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4d07481e76eee43819f93614f7c47384",
     "grade": true,
     "grade_id": "cv_lr_pipe_sw_test",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf3, Pipeline)\n",
    "assert_is_instance(y_pred3, np.ndarray)\n",
    "cv3 = clf3.named_steps['cv']\n",
    "assert_is_instance(cv3, CountVectorizer)\n",
    "assert_is_instance(clf3.named_steps['lr'], LogisticRegression)\n",
    "assert_equal(cv3.stop_words, 'english')\n",
    "assert_equal(len(y_pred3), len(y_test))\n",
    "assert_array_equal(y_pred3[:5], ['osx', 'ajax', 'matlab', 'cocoa', 'matlab'])\n",
    "assert_array_equal(y_pred3[-5:], ['haskell', 'svn', 'drupal', 'cocoa', 'scala'])\n",
    "assert_almost_equal(score3, 0.87239999999999995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline of TF-IDF and Logistic Regression with stop words\n",
    "\n",
    "- Build a pipeline by using `TfidfVectorizer` and `LogisticsRegression`. Name the first step `tf` and the second step `lr`. Use English stop words. Use default parameters for both `TfidfVectorizer` and `LogisticsRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "1da8b80e6a6638e90ad5affec28f83f9",
     "grade": false,
     "grade_id": "tfidf_lr_ans",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tfidf_lr(X_train, y_train, X_test, random_state):\n",
    "    '''\n",
    "    Creates a document term matrix and uses Logistic Regression classifier to make text classifications.\n",
    "    Uses English stop words.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A pd.core.Core. Series object.\n",
    "    y_train: A pd.core.Core. Series object.\n",
    "    X_test: A pd.core.Core. Series object.\n",
    "    random_state: A np.random.RandomState instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (clf, y_pred)\n",
    "    clf: A Pipeline instance.\n",
    "    y_pred: A numpy array.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    tools = [('tf', TfidfVectorizer()), ('lr', LogisticRegression(random_state = random_state))]\n",
    "    clf = Pipeline(tools)\n",
    "    \n",
    "    clf.set_params(tf__stop_words = 'english')\n",
    "    \n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    \n",
    "    return clf, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "fc4a6d2cdba03b49494313e55fd40475",
     "grade": false,
     "grade_id": "tfidf_lr",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR prediction accuracy =  87.2%\n"
     ]
    }
   ],
   "source": [
    "clf4, y_pred4 = tfidf_lr(X_train, y_train, X_test, random_state=check_random_state(0))\n",
    "score4 = accuracy_score(y_pred4, y_test)\n",
    "print(\"LR prediction accuracy = {0:5.1f}%\".format(100.0 * score4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "6a8dd4fed12107597a5feb58eac6c389",
     "grade": true,
     "grade_id": "tfidf_lr_test",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf4, Pipeline)\n",
    "assert_is_instance(y_pred4, np.ndarray)\n",
    "tf4 = clf4.named_steps['tf']\n",
    "assert_is_instance(tf4, TfidfVectorizer)\n",
    "assert_is_instance(clf4.named_steps['lr'], LogisticRegression)\n",
    "assert_equal(tf4.stop_words, 'english')\n",
    "assert_equal(len(y_pred4), len(y_test))\n",
    "assert_array_equal(y_pred4[:5], ['osx', 'ajax', 'matlab', 'cocoa', 'matlab'])\n",
    "assert_array_equal(y_pred4[-5:], ['haskell', 'svn', 'drupal', 'cocoa', 'scala'])\n",
    "assert_almost_equal(score4, 0.872)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
