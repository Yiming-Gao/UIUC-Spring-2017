{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 Problem 3\n",
    "\n",
    "If you are not using the `Assignments` tab on the course JupyterHub server to read this notebook, read [Activating the assignments tab](https://github.com/lcdm-uiuc/info490-sp17/blob/master/help/act_assign_tab.md).\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_  â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded.\n",
    "-----\n",
    "# Problem 7.3. Text Mining\n",
    "In this problem, we use the Brown corpus to perform text mining tasks, such as n-grams, stemming, and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "ff0e58390a8070382e78a276fae0bbc7",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import collections\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "\n",
    "from nose.tools import (\n",
    "    assert_equal,\n",
    "    assert_is_instance,\n",
    "    assert_almost_equal,\n",
    "    assert_true\n",
    ")\n",
    "from numpy.testing import assert_array_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will analyze the NLTK Brown corpus. The Brown Corpus was the first million-word electronic corpus of English, created in 1961 at Brown University. This corpus contains text from 500 sources, and the sources have been categorized by genre, such as news, editorial, and so on. See the [NLTK docs](http://www.nltk.org/book/ch02.html#brown-corpus) for more information.\n",
    "\n",
    "```python\n",
    ">>> print( len( brown.fileids() ) ) # total number of files\n",
    "500\n",
    "\n",
    ">>> print( brown.categories() ) # all genres in corpus\n",
    "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n",
    "```\n",
    "\n",
    "In the Brown corpus, there are 500 files of 15 genres. We could access the raw data and the genre of each file. What we are going to do is make predictions of a file's genre based on its raw data. Since the sample size is not very large, especially for each genre, there is only about 30 files on average. Therefore, we would like to remove genres with few files first.\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "In the following cell, write a function named `select_genres()` that returns raw data (using `raw()`) and genres of files (using `categories()`) whose genres appear more than `n` times in the corpus, where `n` is some integer.  For example, if `n`=70, then you first need to find the genres that have more than 70 files; in this case, they are `learned` or `belles_lettres`; the output should be a tuple of two 1d numpy arrays: raw data of files with selected genres, genres of files with selected genres. Each element in the two output arrays should correspond to the same file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b507eb4da088fbe988f4977a5c69ca3b",
     "grade": false,
     "grade_id": "select",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def select_genres(n):\n",
    "    '''\n",
    "    Selects genres with more than n files. Returns raw data and the genre of each file\n",
    "    in the selected genres as two 1d numpy arrays.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n: An integer.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (raw, genres)\n",
    "    raw: A 1d numpy array.\n",
    "    genres: A 1d numpy array.\n",
    "    '''\n",
    "    num_files = []\n",
    "    raw = []\n",
    "    genres = []\n",
    "\n",
    "    # num_files: number of files in each category\n",
    "    for genre in brown.categories():\n",
    "        num_files.append(len(brown.fileids(categories = genre)))\n",
    "    \n",
    "    index = [i for i,k in enumerate(num_files) if k > n]\n",
    "    # those categories satisfying the condition\n",
    "    categories = np.array(brown.categories())[index]\n",
    "    \n",
    "    # for each fileid, check if its category is in the categories we select previously\n",
    "    for fileid in brown.fileids():\n",
    "        if brown.categories(fileid) in categories:\n",
    "            raw.append(brown.raw(fileid))\n",
    "            genres.append(brown.categories(fileid))\n",
    "            \n",
    "    raw = np.array(raw).ravel()\n",
    "    genres = np.array(genres).ravel()\n",
    "    \n",
    "    return raw, genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8ca338ea061e0dfdea447decafe38e8c",
     "grade": true,
     "grade_id": "select_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "t1_raw, t1_genres = select_genres(70)\n",
    "assert_equal(np.shape(t1_raw), (155,))\n",
    "assert_equal(np.shape(t1_genres), (155,))\n",
    "assert_array_equal(t1_genres, ['belles_lettres']*75+['learned']*80)\n",
    "assert_equal(t1_raw[5][:50], 'Die/fw-at Frist/fw-nn ist/fw-bez um/fw-rb ,/, und/')\n",
    "assert_equal(t1_raw[120][120:160], 'agricultural/jj areas/nns in/in the/at w')\n",
    "\n",
    "t2_raw, t2_genres = select_genres(29)\n",
    "assert_equal(np.shape(t2_raw), (313,))\n",
    "assert_equal(np.shape(t2_genres), (313,))\n",
    "assert_array_equal(t2_genres, ['news']*44+['hobbies']*36+['lore']*48+['belles_lettres']*75+['government']*30+['learned']*80)\n",
    "assert_equal(t2_raw[300][-80:], \" is/bez not/* generally/rb used/vbn over-hand/rb ,/, but/cc under/rb ''/'' ./.\\n\\n\")\n",
    "assert_equal(t2_raw[249][490:530], 's from/in the/at cortex/nn to/in the/at ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Sets\n",
    "\n",
    "Run the cell below to split selected data (We'll use `n`=27) into training and testing sets with a test size of 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ba2acf06ed54959b725227e61bb50296",
     "grade": false,
     "grade_id": "split",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "t_raw, t_genres = select_genres(27)\n",
    "t_X_train, t_X_test, t_y_train, t_y_test = train_test_split(t_raw, \n",
    "                                                            t_genres, \n",
    "                                                            random_state=check_random_state(0), \n",
    "                                                            test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-grams\n",
    "\n",
    "- Use unigrams, bigrams, and trigrams,\n",
    "- Build a pipeline by using `TfidfVectorizer` and `KNeighborsClassifier`,\n",
    "- Name the first step `tf` and the second step `knc`,\n",
    "- Use English stop words,\n",
    "- Convert all words into lower case so that the model does not depend on cases,\n",
    "- Impose a minimum feature term that requires a term to be present in at least 3 documents, \n",
    "- Set a maximum frequency of 70%, such that any term occurring in more than 70% of all documents will be ignored, and\n",
    "- Set the rest parameters to default for both `TfidfVectorizer` and `KNeighborsClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "c1555cce8184ea4dce98b8f6cac09653",
     "grade": false,
     "grade_id": "ngram",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def ngram(X_train, y_train, X_test):\n",
    "    '''\n",
    "    Creates a document term matrix and uses KNC classifier to make document classifications.\n",
    "    Uses unigrams, bigrams, and trigrams.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A 1d numpy array of strings.\n",
    "    y_train: A 1d numpy array of strings.\n",
    "    X_test: A 1d numpy array of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (clf, y_pred)\n",
    "    clf: A Pipeline instance.\n",
    "    y_pred: A 1d numpy array.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    tools = [('tf', TfidfVectorizer()), ('knc', KNeighborsClassifier())]\n",
    "    clf = Pipeline(tools)\n",
    "    clf.set_params(tf__stop_words = 'english',\n",
    "                   tf__ngram_range = (1, 3),\n",
    "                   tf__max_df = 0.7,\n",
    "                   tf__min_df = 3,\n",
    "                   tf__lowercase = True\n",
    "                  )\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    return clf, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7e7ed9c46c1d569a5c1c723e51673dd3",
     "grade": false,
     "grade_id": "ngram_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNC prediction accuracy =  52.5%\n"
     ]
    }
   ],
   "source": [
    "clf1, y_pred1 = ngram(t_X_train, t_y_train, t_X_test)\n",
    "score1 = accuracy_score(y_pred1, t_y_test)\n",
    "print(\"KNC prediction accuracy = {0:5.1f}%\".format(100.0 * score1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "03f9b558528f0595f327de4ad7daad1f",
     "grade": true,
     "grade_id": "ngram_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf1, Pipeline)\n",
    "assert_is_instance(y_pred1, np.ndarray)\n",
    "tf1 = clf1.named_steps['tf']\n",
    "assert_is_instance(tf1, TfidfVectorizer)\n",
    "assert_is_instance(clf1.named_steps['knc'], KNeighborsClassifier)\n",
    "assert_equal(tf1.stop_words, 'english')\n",
    "assert_equal(tf1.ngram_range, (1, 3))\n",
    "assert_equal(tf1.min_df, 3)\n",
    "assert_equal(tf1.max_df, 0.7)\n",
    "assert_equal(len(y_pred1), len(t_y_test))\n",
    "assert_array_equal(y_pred1[:5], ['belles_lettres', 'government', 'romance', 'belles_lettres', 'government'])\n",
    "assert_array_equal(y_pred1[-5:], ['government', 'lore', 'government', 'learned', 'adventure'])\n",
    "assert_almost_equal(score1, 0.52500000000000002)               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "\n",
    "- Modify the `tokenize` function from [Introduction to Text Mining notebook](../../notebooks/intro2tm.ipynb). Use [Snowball](http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.snowball) stemming algorithm instead of Porter Stemmer,\n",
    "- Use unigrams, bigrams, and trigrams, \n",
    "- Build a pipeline by using `TfidfVectorizer` and `KNeighborsClassifier`,\n",
    "- Name the first step `tf` and the second step `knc`,\n",
    "- Use English stop words,\n",
    "- Convert all words into lower case so that the model does not depend on cases,\n",
    "- Impose a minimum feature term that requires a term to be present in at least 3 documents, \n",
    "- Set a maximum frequency of 70%, such that any term occurring in more than 70% of all documents will be ignored, and\n",
    "- Set the rest parameters to default for both `TfidfVectorizer` and `KNeighborsClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "cd86ad615f53aa3a0a14d2faf19139a3",
     "grade": false,
     "grade_id": "tokenize",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    '''\n",
    "    Converts text into tokens. Same function as in the \"introduction to text mining\" notebook.\n",
    "    Uses Snowball Stemmer.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: a string.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tokens: a map object.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in string.punctuation]\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stems = map(stemmer.stem, tokens)\n",
    "    \n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "8e49c8db07447daf144b1445dea477b6",
     "grade": false,
     "grade_id": "stem",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def stem(X_train, y_train, X_test):\n",
    "    '''\n",
    "    Creates a document term matrix and uses KNC classifier to make document classifications.\n",
    "    Uses the Snowball stemmer.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A 1d numpy array of strings.\n",
    "    y_train: A 1d numpy array of strings.\n",
    "    X_test: A 1d numpy array of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (clf, y_pred)\n",
    "    clf: A Pipeline instance.\n",
    "    y_pred: A 1d numpy array.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    tools = [('tf', TfidfVectorizer()), ('knc', KNeighborsClassifier())]\n",
    "    clf = Pipeline(tools)\n",
    "    clf.set_params(tf__stop_words = 'english',\n",
    "                   tf__ngram_range = (1, 3),\n",
    "                   tf__max_df = 0.7,\n",
    "                   tf__min_df = 3,\n",
    "                   tf__tokenizer = tokenize,\n",
    "                   tf__lowercase = True\n",
    "                  )\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    return clf, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ca49ad35b718f2c1f07b59dc8f33fc2a",
     "grade": false,
     "grade_id": "stem_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNC prediction accuracy =  42.0%\n"
     ]
    }
   ],
   "source": [
    "# use sliced arrays to save execution time\n",
    "# you should try use original data and compare predcition accurary\n",
    "clf2, y_pred2 = stem(t_X_train[:100], t_y_train[:100], t_X_test[:50])\n",
    "score2 = accuracy_score(y_pred2, t_y_test[:50])\n",
    "print(\"KNC prediction accuracy = {0:5.1f}%\".format(100.0 * score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "f8c2a72b4cb51430212c04cf759643bc",
     "grade": true,
     "grade_id": "stem_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf2, Pipeline)\n",
    "assert_is_instance(y_pred2, np.ndarray)\n",
    "tf2 = clf2.named_steps['tf']\n",
    "assert_is_instance(tf2, TfidfVectorizer)\n",
    "assert_is_instance(clf2.named_steps['knc'], KNeighborsClassifier)\n",
    "assert_equal(tf2.stop_words, 'english')\n",
    "assert_equal(tf2.ngram_range, (1, 3))\n",
    "assert_equal(tf2.min_df, 3)\n",
    "assert_equal(tf2.max_df, 0.7)\n",
    "\n",
    "assert_equal(len(y_pred2), 50)\n",
    "assert_array_equal(y_pred2[:5], ['lore', 'learned', 'romance', 'belles_lettres', 'learned'])\n",
    "assert_array_equal(y_pred2[-5:], ['fiction', 'romance', 'belles_lettres', 'romance', 'learned'])\n",
    "assert_almost_equal(score2, 0.41999999999999998 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Analysis\n",
    "\n",
    "- Build a pipeline by using `TfidfVectorizer` and `KMeans`,\n",
    "- Name the first step `tf` and the second step `km`,\n",
    "- Use unigrams only,\n",
    "- Use English stop words, \n",
    "- Convert all words into lower case so that the model does not depend on cases,\n",
    "- Impose a minimum feature term that requires a term to be present in at least 3 documents, \n",
    "- Set a maximum frequency of 70%, such that any term occurring in more than 70% of all documents will be ignored,\n",
    "- Set the number of clusters equal to `k`,\n",
    "- Set the rest parameters to default for both `TfidfVectorizer` and `KNeighborsClassifier`, and \n",
    "- Identify the most frequently used words for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "bf2cef3efc24a1f3d9937b4fd61135aa",
     "grade": false,
     "grade_id": "tokens",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_top_tokens(X_train, y_train, X_test, random_state, k, n):\n",
    "    '''\n",
    "    First, applies clustering analysis to a feature matrix.\n",
    "    Then, identifies the most frequently used words in \"icluster\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A 1d numpy array of strings.\n",
    "    y_train: A 1d numpy array of strings.\n",
    "    X_test: A 1d numpy array of strings.\n",
    "    random_state: A np.random.RandomState instance for KMeans.\n",
    "    k: An int. The number of clusters.\n",
    "    n: An int. Specifies how many tokens for each cluster should be returned.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    clf: A Pipeline instance.\n",
    "    tokens: A 2d numpy array of strings with shape of (n_clusters, n_tokens of each cluster)\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    tools = [('tf', TfidfVectorizer()), ('km', KMeans())]\n",
    "    clf = Pipeline(tools)\n",
    "    clf.set_params(tf__stop_words = 'english',\n",
    "                   tf__max_df = 0.7,\n",
    "                   tf__min_df = 3,\n",
    "                   tf__lowercase = True,\n",
    "                   km__n_clusters = k,\n",
    "                   km__random_state = random_state\n",
    "                  )\n",
    "    clf.fit(X_train)\n",
    "    \n",
    "    # name the model\n",
    "    km = clf.named_steps['km']\n",
    "    tf = clf.named_steps['tf']\n",
    "    \n",
    "    order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "    terms = tf.get_feature_names()\n",
    "    tokens = []\n",
    "\n",
    "    for idx in range(k):\n",
    "        for jdx in order_centroids[idx, :n]:\n",
    "            tokens.append(terms[jdx])\n",
    "    \n",
    "    # rearrange the array\n",
    "    tokens = np.reshape(tokens, (k, n))\n",
    "    \n",
    "    return clf, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "13c321b9196fff2b3ec3eaa279ab3986",
     "grade": false,
     "grade_id": "tokens_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 tokens per cluster:\n",
      "---------------------------------------------\n",
      "Cluster 0: fw nil bridge pont nps\n",
      "Cluster 1: men man said eyes dod\n",
      "Cluster 2: hl costs shelter foam foods\n",
      "Cluster 3: college mrs students school education\n",
      "Cluster 4: said dod uh ll bem\n",
      "Cluster 5: hl nps state president law\n",
      "Cluster 6: hl year tax sales 1960\n",
      "Cluster 7: af hl temperature pressure fig\n",
      "Cluster 8: nc fw man human experience\n"
     ]
    }
   ],
   "source": [
    "k3 = len(np.unique(t_genres))\n",
    "n3 = 5\n",
    "clf3, tokens3 = get_top_tokens(t_X_train, t_y_train, t_X_test, check_random_state(0), k3, n3)\n",
    "print('Top {} tokens per cluster:'.format(n3))\n",
    "print('-'*45)\n",
    "for i in range(k3):\n",
    "    print(\"Cluster {0}: {1}\".format(i, ' '.join(tokens3[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7bb9bf64d2b55a4a4a6112e653a35a03",
     "grade": true,
     "grade_id": "tokens_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf3, Pipeline)\n",
    "tf3 = clf3.named_steps['tf']\n",
    "assert_is_instance(tf3, TfidfVectorizer)\n",
    "km3 = clf3.named_steps['km']\n",
    "assert_is_instance(km3, KMeans)\n",
    "assert_equal(tf3.stop_words, 'english')\n",
    "assert_equal(tf3.ngram_range, (1, 1))\n",
    "assert_equal(tf3.min_df, 3)\n",
    "assert_equal(tf3.max_df, 0.7)\n",
    "assert_equal(km3.n_clusters, k3)\n",
    "assert_equal(np.shape(tokens3), (9, 5))\n",
    "assert_array_equal(tokens3, [['fw', 'nil', 'bridge', 'pont', 'nps'],\n",
    "                             ['men', 'man', 'said', 'eyes', 'dod'],\n",
    "                             ['hl', 'costs', 'shelter', 'foam', 'foods'],\n",
    "                             ['college', 'mrs', 'students', 'school', 'education'],\n",
    "                             ['said', 'dod', 'uh', 'll', 'bem'],\n",
    "                             ['hl', 'nps', 'state', 'president', 'law'],\n",
    "                             ['hl', 'year', 'tax', 'sales', '1960'],\n",
    "                             ['af', 'hl', 'temperature', 'pressure', 'fig'],\n",
    "                             ['nc', 'fw', 'man', 'human', 'experience']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "32b575ecfd7687271bf06e537410c5fc",
     "grade": true,
     "grade_id": "tokens_test_2",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "clf4, tokens4 = get_top_tokens(t_X_train, t_y_train, t_X_test, check_random_state(0), k3, 3)\n",
    "assert_array_equal(tokens4[0], ['fw', 'nil', 'bridge'])\n",
    "assert_array_equal(tokens4[6], ['hl', 'year', 'tax'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
