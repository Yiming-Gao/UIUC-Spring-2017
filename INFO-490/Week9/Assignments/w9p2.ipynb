{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1891bdcd87c6c960df75b6e90b02b234",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "If you are not using the `Assignments` tab on the course JupyterHub server to read this notebook, read [Activating the assignments tab](https://github.com/lcdm-uiuc/info490-sp17/blob/master/help/act_assign_tab.md).\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_ â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cff737ab04ed5f48f39a33ba2b9ead9e",
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Problem 9.2. NLP: Topic Modeling.\n",
    "\n",
    "In this problem, we explore the concept of topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "55ab0d334275e9470adb6d10466fc36d",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from scipy.sparse.csr import csr_matrix\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.cross_validation import check_random_state\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from gensim.matutils import Sparse2Corpus\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance, assert_true, assert_almost_equal\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "49943f029f58697ca90647268f1b2467",
     "grade": false,
     "grade_id": "markdown_1",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "We will be using the reuters data (nltk.corpus.reuters). The X_train, X_test, y_train, and y_test have already been preprocessed and saved in JSON format, for convenience in the `/home/data_scientist/data/misc` directory. Using the code below, we will fetch them for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a9dedd22f27d222a6c0bf31912aaaab4",
     "grade": false,
     "grade_id": "reuters",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_reuters(name):\n",
    "    fpath = '/home/data_scientist/data/misc/reuters_{}.json'.format(name)\n",
    "    with open(fpath) as f:\n",
    "        reuters = json.load(f)\n",
    "    return reuters\n",
    "\n",
    "X_train, X_test, y_train, y_test = map(load_reuters, ['X_train', 'X_test', 'y_train', 'y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ec746983cffee5ae55180f441ee3716f",
     "grade": false,
     "grade_id": "markdown_2",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Document term matrix\n",
    "\n",
    "- Use TfidfVectorizer to create a document term matrix for both `X_train` and `X_test`.\n",
    "- Use English stop words.\n",
    "- Use unigrams and bigrams.\n",
    "- Ignore terms that have a document frequency strictly lower than 2.\n",
    "- Build a vocabulary that only consider the top 20,000 features ordered by term frequency across the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "36a64e0bacc6868463950e6d8fd4d0ff",
     "grade": false,
     "grade_id": "get_document_term_matrix_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_document_term_matrix(train_data, test_data):\n",
    "    '''\n",
    "    Uses TfidfVectorizer to create a document term matrix for \"X_train\" and \"X_test\".\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    train_data: A list of strings\n",
    "    test_data:A list of strings\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 3-tuple of (model, train_matrix, test_matrix).\n",
    "    model: A TfidfVectorizer instance\n",
    "    train_matrix: A scipy.csr_matrix\n",
    "    test_matrix: A scipy.csr_matrix\n",
    "    '''\n",
    "    \n",
    "    # train a model\n",
    "    model = TfidfVectorizer(stop_words = 'english',\n",
    "                            lowercase = True,\n",
    "                            min_df = 2,\n",
    "                            max_features = 20000,\n",
    "                            ngram_range = (1,2))\n",
    "    # document term matrix\n",
    "    train_matrix = model.fit_transform(train_data)\n",
    "    test_matrix = model.transform(test_data)\n",
    "    \n",
    "    return model, train_matrix, test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c31f6bd9fde2905cff19bf5c31a5d144",
     "grade": false,
     "grade_id": "get_document_term_matrix_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "cv, train_data, test_data = get_document_term_matrix(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "53b6fdecf40744f94323b5d6d811a9b2",
     "grade": true,
     "grade_id": "get_document_term_matrix_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(cv, TfidfVectorizer)\n",
    "assert_is_instance(train_data, csr_matrix)\n",
    "assert_is_instance(test_data, csr_matrix)\n",
    "assert_equal(cv.stop_words, 'english')\n",
    "assert_equal(cv.ngram_range, (1, 2))\n",
    "assert_equal(cv.min_df, 2)\n",
    "assert_equal(cv.max_features, 20000)\n",
    "assert_equal(train_data.data.size, 588963)\n",
    "assert_array_almost_equal(\n",
    "    train_data.data[:5],\n",
    "    [0.0375267,   0.0401517,   0.03477509,  0.0474274,   0.03217005]\n",
    "    )\n",
    "assert_equal(test_data.data.size, 210403)\n",
    "assert_array_almost_equal(\n",
    "    test_data.data[:5],\n",
    "    [ 0.02399319,  0.04801429,  0.04859632,  0.0403796,   0.0403796]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0c94a4f3e3244ae3a1e134a7913a332c",
     "grade": false,
     "grade_id": "markdown_3",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Non-negative matrix factorization\n",
    "\n",
    "- Apply non-negative matrix factorization (NMF) to compute topics in `train_data`.\n",
    "- Use 60 topics.\n",
    "- Normalize the transformed data to have unit probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7c010d77b4730bf96cd1a4d64b1fcc86",
     "grade": false,
     "grade_id": "apply_nmf_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def apply_nmf(data, random_state):\n",
    "    '''\n",
    "    Applies non-negative matrix factorization (NMF) to compute topics.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: A csr_matrix\n",
    "    random_state: A RandomState instance for NMF\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (nmf, transformed_data)\n",
    "    nmf: An sklearn.NMF instance\n",
    "    transformed_data: A numpy.ndarray\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    nmf = NMF(n_components = 60, random_state = random_state).fit(data)\n",
    "    \n",
    "    # We transform and normalize the data, \n",
    "    # by using l1 so document topic probabilty sums to unity.\n",
    "    td = nmf.transform(data)\n",
    "    transformed_data = normalize(td, norm = 'l1', axis = 1)\n",
    "    \n",
    "    return nmf, transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "426f1943e7092db4fc3265eda44efb8e",
     "grade": false,
     "grade_id": "apply_nmf_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "nmf, td_norm = apply_nmf(train_data, random_state=check_random_state(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "096ee9f6fd26db25ef77c7368187b657",
     "grade": true,
     "grade_id": "apply_nmf_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(nmf, NMF)\n",
    "assert_is_instance(td_norm, np.ndarray)\n",
    "assert_equal(nmf.n_components, 60)\n",
    "assert_equal(nmf.max_iter, 200)\n",
    "assert_equal(td_norm.shape, (7769, 60))\n",
    "assert_array_almost_equal(\n",
    "    td_norm[0, :5],\n",
    "    [0. ,         0.08515023,  0.01682892,  0.,          0.02451052]\n",
    "    )\n",
    "assert_array_almost_equal(\n",
    "    td_norm[-1, -5:],\n",
    "    [  0.,          0.,          0.,         0.00342309,  0.        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "732c13b46243eb41c9197e60fd6fcf1a",
     "grade": false,
     "grade_id": "mardkwon_4",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Topic-based Classification\n",
    "\n",
    "- Train a LinearSVC classifier on the topics in the training data sample of the reuters data set.\n",
    "- Use default parameters for the LinearSVC classifier. Don't forget to set the `random_state` parameter.\n",
    "- Compute the topics, by using the previously created NMF model, for the test data and compute classifications from these topic models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e721041a23a65c25ac1df44cce6cf46a",
     "grade": false,
     "grade_id": "classify_topics_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def classify_topics(nmf, X_train, y_train, X_test, random_state):\n",
    "    '''\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    nmf: An sklearn.NMF model.\n",
    "    X_train: A numpy array.\n",
    "    y_train: A numpy array.\n",
    "    X_test: A scipy csr_matrix.\n",
    "    random_state: A RandomState instance for LinearSVC Classifier.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (clf, y_pred)\n",
    "    clf: A LinearSVC instance.\n",
    "    y_pred: A numpy array.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    clf = LinearSVC(random_state = random_state)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(nmf.transform(X_test))\n",
    "    \n",
    "    return clf, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "950e39736150bc81546612927ba39e78",
     "grade": false,
     "grade_id": "classify_topics_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "clf, ts_preds = classify_topics(\n",
    "    nmf, nmf.transform(train_data), y_train, test_data, check_random_state(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "184527224b84b48683d1a143d0f07be9",
     "grade": true,
     "grade_id": "classify_topics_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf, LinearSVC)\n",
    "assert_is_instance(ts_preds, np.ndarray)\n",
    "assert_equal(len(ts_preds), len(y_test))\n",
    "assert_array_equal(ts_preds[:5], ['trade', 'grain', 'crude', 'earn', 'crude'])\n",
    "assert_array_equal(ts_preds[-5:], ['acq', 'dlr', 'crude', 'grain', 'acq'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7338bc8d00ad62d31633076c99264b40",
     "grade": false,
     "grade_id": "markdown_6",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Topic Modeling with Gensim\n",
    "\n",
    "- Use the gensim library to perform topic modeling of the reuters data. First transform a sparse matrix into a gensim corpus, and then construct a vocabulary dictionary. Finally, create a  Latent Dirichlet allocation (LDA) model with 20 topics for the reuters text, and return 5 most significant words for each topic.\n",
    "- You should specify three parameters in `LdaModel()`: `corpus`, `id2word`, and `num_topics`. Use default values for all other paramters. Ignore any warnings about `passes` or `iterations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0cf95c209cf1ec904cd96672108ebde0",
     "grade": false,
     "grade_id": "get_topics_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_topics(cv, train_data):\n",
    "    '''\n",
    "    Uses gensim to perform topic modeling.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    cv: A TfidfVectorizer instance.\n",
    "    train_data: A scipy csr_matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of strings (functions of the most important terms in each topic).\n",
    "    '''\n",
    "    \n",
    "    # transform sparse matrix into gensim corpus\n",
    "    td_gensim = Sparse2Corpus(train_data, documents_columns = False)\n",
    "    # Build temporary dictionary from scikit learn vectorizer\n",
    "    # for use with gensim\n",
    "    tmp_dct = dict((idv, word) for word, idv in cv.vocabulary_.items())\n",
    "    dct = Dictionary.from_corpus(td_gensim, id2word = tmp_dct)\n",
    "    # LDA\n",
    "    lda_gs = LdaModel(corpus = td_gensim, id2word = dct, num_topics = 20)\n",
    "    topics = lda_gs.top_topics(corpus = td_gensim, num_words = 5)\n",
    "    \n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a59f5f881e6e96f699813e444c0ba77d",
     "grade": false,
     "grade_id": "get_topics_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0\n",
      "-----------------------------------\n",
      "    vs                  : 0.0062\n",
      "    000                 : 0.0050\n",
      "    loss                : 0.0042\n",
      "    cts                 : 0.0037\n",
      "    mln                 : 0.0031\n",
      "-----------------------------------\n",
      "Topic 1\n",
      "-----------------------------------\n",
      "    said                : 0.0058\n",
      "    company             : 0.0035\n",
      "    dlrs                : 0.0031\n",
      "    mln                 : 0.0028\n",
      "    lt                  : 0.0027\n",
      "-----------------------------------\n",
      "Topic 2\n",
      "-----------------------------------\n",
      "    vs                  : 0.0300\n",
      "    mln                 : 0.0175\n",
      "    000                 : 0.0172\n",
      "    loss                : 0.0157\n",
      "    net                 : 0.0156\n",
      "-----------------------------------\n",
      "Topic 3\n",
      "-----------------------------------\n",
      "    francs              : 0.0044\n",
      "    mln                 : 0.0043\n",
      "    bank                : 0.0036\n",
      "    said                : 0.0034\n",
      "    billion             : 0.0028\n",
      "-----------------------------------\n",
      "Topic 4\n",
      "-----------------------------------\n",
      "    cts                 : 0.0187\n",
      "    qtly                : 0.0158\n",
      "    div                 : 0.0152\n",
      "    april               : 0.0141\n",
      "    qtly div            : 0.0137\n",
      "-----------------------------------\n",
      "Topic 5\n",
      "-----------------------------------\n",
      "    1987                : 0.0056\n",
      "    said                : 0.0054\n",
      "    dlrs                : 0.0047\n",
      "    billion             : 0.0047\n",
      "    year                : 0.0046\n",
      "-----------------------------------\n",
      "Topic 6\n",
      "-----------------------------------\n",
      "    fed                 : 0.0088\n",
      "    customer            : 0.0058\n",
      "    repurchase          : 0.0045\n",
      "    customer repurchase : 0.0045\n",
      "    repurchase agreements: 0.0038\n",
      "-----------------------------------\n",
      "Topic 7\n",
      "-----------------------------------\n",
      "    said                : 0.0078\n",
      "    pct                 : 0.0062\n",
      "    billion             : 0.0037\n",
      "    dlrs                : 0.0033\n",
      "    bank                : 0.0029\n",
      "-----------------------------------\n",
      "Topic 8\n",
      "-----------------------------------\n",
      "    said                : 0.0062\n",
      "    shares              : 0.0051\n",
      "    lt                  : 0.0037\n",
      "    dlrs                : 0.0036\n",
      "    stake               : 0.0034\n",
      "-----------------------------------\n",
      "Topic 9\n",
      "-----------------------------------\n",
      "    said                : 0.0093\n",
      "    trade               : 0.0049\n",
      "    pct                 : 0.0043\n",
      "    japan               : 0.0040\n",
      "    oil                 : 0.0033\n",
      "-----------------------------------\n",
      "Topic 10\n",
      "-----------------------------------\n",
      "    vs                  : 0.0111\n",
      "    mln                 : 0.0080\n",
      "    cts                 : 0.0073\n",
      "    record march        : 0.0056\n",
      "    dividend            : 0.0043\n",
      "-----------------------------------\n",
      "Topic 11\n",
      "-----------------------------------\n",
      "    pay march           : 0.0038\n",
      "    moore               : 0.0029\n",
      "    pct official        : 0.0028\n",
      "    guinness            : 0.0022\n",
      "    said                : 0.0021\n",
      "-----------------------------------\n",
      "Topic 12\n",
      "-----------------------------------\n",
      "    10 record           : 0.0039\n",
      "    hughes              : 0.0032\n",
      "    maize               : 0.0023\n",
      "    financial statements: 0.0022\n",
      "    units               : 0.0018\n",
      "-----------------------------------\n",
      "Topic 13\n",
      "-----------------------------------\n",
      "    said                : 0.0038\n",
      "    gencorp             : 0.0036\n",
      "    gulf                : 0.0031\n",
      "    44 cts              : 0.0023\n",
      "    mln                 : 0.0022\n",
      "-----------------------------------\n",
      "Topic 14\n",
      "-----------------------------------\n",
      "    quarterly qtly      : 0.0106\n",
      "    sets quarterly      : 0.0097\n",
      "    10 cts              : 0.0037\n",
      "    div 10              : 0.0027\n",
      "    federal             : 0.0027\n",
      "-----------------------------------\n",
      "Topic 15\n",
      "-----------------------------------\n",
      "    dlrs                : 0.0038\n",
      "    express             : 0.0036\n",
      "    american express    : 0.0035\n",
      "    mln                 : 0.0031\n",
      "    allegheny           : 0.0028\n",
      "-----------------------------------\n",
      "Topic 16\n",
      "-----------------------------------\n",
      "    bank                : 0.0052\n",
      "    stg                 : 0.0052\n",
      "    mln stg             : 0.0048\n",
      "    market              : 0.0047\n",
      "    baker               : 0.0046\n",
      "-----------------------------------\n",
      "Topic 17\n",
      "-----------------------------------\n",
      "    pct                 : 0.0093\n",
      "    february            : 0.0065\n",
      "    split               : 0.0059\n",
      "    said                : 0.0054\n",
      "    cyclops             : 0.0054\n",
      "-----------------------------------\n",
      "Topic 18\n",
      "-----------------------------------\n",
      "    said                : 0.0035\n",
      "    chrysler            : 0.0035\n",
      "    cyacq               : 0.0032\n",
      "    lt                  : 0.0031\n",
      "    caesars             : 0.0030\n",
      "-----------------------------------\n",
      "Topic 19\n",
      "-----------------------------------\n",
      "    rubber              : 0.0043\n",
      "    1st half            : 0.0033\n",
      "    amstutz             : 0.0032\n",
      "    20 record           : 0.0028\n",
      "    shr diluted         : 0.0028\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "topics = get_topics(cv, train_data)\n",
    "\n",
    "for idx, (lst, val) in enumerate(topics):\n",
    "    print('Topic {0}'.format(idx))\n",
    "    print(35*('-'))\n",
    "    for i, z in lst:\n",
    "        print('    {0:20s}: {1:5.4f}'.format(z, i))\n",
    "    print(35*('-'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a9979dc296f99568d488105aa65a8bdb",
     "grade": true,
     "grade_id": "get_topics_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(topics, list)\n",
    "assert_equal(len(topics), 20)\n",
    "\n",
    "for topic, score in topics:\n",
    "    assert_is_instance(topic, list)\n",
    "    assert_is_instance(score, float)\n",
    "    assert_equal(len(topic), 5)\n",
    "    for v, k in topic:\n",
    "        assert_is_instance(k, str)\n",
    "        assert_is_instance(v, float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline of FeatureUnion and Logistic Regression\n",
    "\n",
    "- Build a pipeline by using [FeatureUnion](http://scikit-learn.org/stable/auto_examples/hetero_feature_union.html) of  and  `LinearSVC`. \n",
    "- A FeatureUnion helps process data in parallel and can be considered pipelines themselves (check this [resource](http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html) for an overview on how FeatureUnion is used in NLP).\n",
    "- The first step of the pipeline should use the FeatureUnion with the name `features`. The first component of the FeatureUnion should contain the `CountVectorizer`, using the name `cv` , followed by the `TfidfVectorizer` using the name `tf`. \n",
    "- The second step of the pipeline should be `LinearSVC` with the name `svc`.\n",
    "- Do not use stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2df182ee3bda6962e202552bcdb35044",
     "grade": false,
     "grade_id": "cv_tfidf_svc_pipe_ans",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def cv_tfidf_svc_pipe(X_train, y_train, X_test, random_state):\n",
    "    '''\n",
    "    Creates a document term matrix and uses SVM classifier to make document classifications.\n",
    "    Uses English stop words.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A list of strings.\n",
    "    y_train: A list of strings.\n",
    "    X_test: A list of strings.\n",
    "    random_state: A np.random.RandomState instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (clf, y_pred)\n",
    "    clf: A Pipeline instance.\n",
    "    y_pred: A numpy array.\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    tools = [('features', FeatureUnion([('cv', CountVectorizer()),\n",
    "                                        ('tf', TfidfVectorizer())])), \n",
    "             ('svc', LinearSVC(random_state = random_state))]\n",
    "    clf = Pipeline(tools)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    \n",
    "    return clf, predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5439acb7dde999c9fa0491b4d7c0cb0b",
     "grade": false,
     "grade_id": "cv_tfidf_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC prediction accuracy = 88.4%\n"
     ]
    }
   ],
   "source": [
    "clf2, y_pred2 = cv_tfidf_svc_pipe(X_train, y_train, X_test, random_state=check_random_state(0))\n",
    "score2 = accuracy_score(y_pred2, y_test)\n",
    "print(\"SVC prediction accuracy = {0:3.1f}%\".format(100.0 * score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "356657210c9041ab4e66120d53d310a2",
     "grade": true,
     "grade_id": "cv_tfidf_svc_pipe_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(clf2, Pipeline)\n",
    "assert_is_instance(y_pred2, np.ndarray)\n",
    "assert_is_instance(clf2.named_steps['features'], FeatureUnion)\n",
    "assert_is_instance(clf2.named_steps['svc'], LinearSVC)\n",
    "assert_is_instance(clf2.named_steps['features'].transformer_list[0][1], CountVectorizer)\n",
    "assert_is_instance(clf2.named_steps['features'].transformer_list[1][1], TfidfVectorizer)\n",
    "assert_equal(len(y_pred2), len(y_test))\n",
    "assert_array_equal(y_pred2[:5], ['trade', 'grain', 'crude', 'corn', 'palm-oil'])\n",
    "assert_array_equal(y_pred2[-5:], ['acq', 'dlr', 'earn', 'ipi', 'gold'])\n",
    "assert_almost_equal(score2, 0.884067572044, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
