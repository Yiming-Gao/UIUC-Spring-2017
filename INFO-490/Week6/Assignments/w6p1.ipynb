{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not using the `Assignments` tab on the course JupyterHub server to read this notebook, read [Activating the assignments tab](https://github.com/lcdm-uiuc/info490-sp17/blob/master/help/act_assign_tab.md).\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_  â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded.\n",
    "\n",
    "# Problem 6.1. Recommender Systems.\n",
    "\n",
    "For this problem, we will be creating a single user recommender system that will consider unfavorable as well as favorable ratings with the help of the [Book-Crossing Dataset](http://www2.informatik.uni-freiburg.de/~cziegler/BX/).  The Book-Crossing Dataset was created by Cai-Nicolas Ziegler in 2004 and used data from the [Book-Crossing Website](http://www.bookcrossing.com/).  These datafiles contain information about the books in circulation, ratings that users have given the books, and information on the users themselves.\n",
    "\n",
    "As usual, we first import the modules needed, and we will also be creating a sandbox directory within our current directory to hold our datafiles for the Book-Crossing Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "416a5f59f49284654a5a4d8c6e34a9cd",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# We do this to ignore several specific Pandas warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "\n",
    "from nose.tools import assert_equal, assert_almost_equal\n",
    "\n",
    "data_dir = '/home/data_scientist/data/book-crossing'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "Now that the data has been downloaded, I will translate the CSV files into Pandas Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 6452: expected 8 fields, saw 9\\nSkipping line 43667: expected 8 fields, saw 10\\nSkipping line 51751: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 92038: expected 8 fields, saw 9\\nSkipping line 104319: expected 8 fields, saw 9\\nSkipping line 121768: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 144058: expected 8 fields, saw 9\\nSkipping line 150789: expected 8 fields, saw 9\\nSkipping line 157128: expected 8 fields, saw 9\\nSkipping line 180189: expected 8 fields, saw 9\\nSkipping line 185738: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 209388: expected 8 fields, saw 9\\nSkipping line 220626: expected 8 fields, saw 9\\nSkipping line 227933: expected 8 fields, saw 11\\nSkipping line 228957: expected 8 fields, saw 10\\nSkipping line 245933: expected 8 fields, saw 9\\nSkipping line 251296: expected 8 fields, saw 9\\nSkipping line 259941: expected 8 fields, saw 9\\nSkipping line 261529: expected 8 fields, saw 9\\n'\n"
     ]
    }
   ],
   "source": [
    "ratings_file = os.path.join(data_dir, 'BX-Book-Ratings.csv')\n",
    "books_file = os.path.join(data_dir, 'BX-Books.csv')\n",
    "users_file = os.path.join(data_dir, 'BX-Users.csv')\n",
    "\n",
    "ratings = pd.read_csv(ratings_file, sep=';', encoding = 'latin1')\n",
    "books = pd.read_csv(books_file, sep=';', error_bad_lines = False, encoding = 'latin1')\n",
    "users = pd.read_csv(users_file, sep=';', encoding = 'latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset is so large, we can only look at about half of the ratings.  Now, let's look at the structure of the dataframes so that we may gain some intuition about how we can best use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ratings[0:500000]\n",
    "print(len(ratings))\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271355</th>\n",
       "      <td>0440400988</td>\n",
       "      <td>There's a Bat in Bunk Five</td>\n",
       "      <td>Paula Danziger</td>\n",
       "      <td>1988</td>\n",
       "      <td>Random House Childrens Pub (Mm)</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271356</th>\n",
       "      <td>0525447644</td>\n",
       "      <td>From One to One Hundred</td>\n",
       "      <td>Teri Sloat</td>\n",
       "      <td>1991</td>\n",
       "      <td>Dutton Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271357</th>\n",
       "      <td>006008667X</td>\n",
       "      <td>Lily Dale : The True Story of the Town that Ta...</td>\n",
       "      <td>Christine Wicker</td>\n",
       "      <td>2004</td>\n",
       "      <td>HarperSanFrancisco</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271358</th>\n",
       "      <td>0192126040</td>\n",
       "      <td>Republic (World's Classics)</td>\n",
       "      <td>Plato</td>\n",
       "      <td>1996</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271359</th>\n",
       "      <td>0767409752</td>\n",
       "      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n",
       "      <td>Christopher  Biffle</td>\n",
       "      <td>2000</td>\n",
       "      <td>McGraw-Hill Humanities/Social Sciences/Languages</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN                                         Book-Title  \\\n",
       "271355  0440400988                         There's a Bat in Bunk Five   \n",
       "271356  0525447644                            From One to One Hundred   \n",
       "271357  006008667X  Lily Dale : The True Story of the Town that Ta...   \n",
       "271358  0192126040                        Republic (World's Classics)   \n",
       "271359  0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n",
       "\n",
       "                Book-Author Year-Of-Publication  \\\n",
       "271355       Paula Danziger                1988   \n",
       "271356           Teri Sloat                1991   \n",
       "271357     Christine Wicker                2004   \n",
       "271358                Plato                1996   \n",
       "271359  Christopher  Biffle                2000   \n",
       "\n",
       "                                               Publisher  \\\n",
       "271355                   Random House Childrens Pub (Mm)   \n",
       "271356                                      Dutton Books   \n",
       "271357                                HarperSanFrancisco   \n",
       "271358                           Oxford University Press   \n",
       "271359  McGraw-Hill Humanities/Social Sciences/Languages   \n",
       "\n",
       "                                              Image-URL-S  \\\n",
       "271355  http://images.amazon.com/images/P/0440400988.0...   \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                              Image-URL-M  \\\n",
       "271355  http://images.amazon.com/images/P/0440400988.0...   \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...   \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...   \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...   \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...   \n",
       "\n",
       "                                              Image-URL-L  \n",
       "271355  http://images.amazon.com/images/P/0440400988.0...  \n",
       "271356  http://images.amazon.com/images/P/0525447644.0...  \n",
       "271357  http://images.amazon.com/images/P/006008667X.0...  \n",
       "271358  http://images.amazon.com/images/P/0192126040.0...  \n",
       "271359  http://images.amazon.com/images/P/0767409752.0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making the Book/Rating Dataframe\n",
    "In order to find what rating a certain user gave a movie, we should combine the books and ratings dataframe on their common column (ISBN) in order to create a new table.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0b7bfb511ab65a71d2cb829485286e44",
     "grade": false,
     "grade_id": "combine",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def combine(bks, rtgs):\n",
    "    '''\n",
    "    Combines the books and ratings dataframes on their common column: their\n",
    "    ISBN numbers.  We then return the newly combined dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bks: A pandas.Dataframe\n",
    "    rtgs: A pandas.Dataframe\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pandas.Dataframe\n",
    "    '''\n",
    "    # Merge two dataframes, the common column is selected aotumatically\n",
    "    bk_rt = pd.merge(bks, rtgs)\n",
    "    \n",
    "    return bk_rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "388c6207a341ce1eca458c245ecdb0ab",
     "grade": true,
     "grade_id": "combine_test",
     "locked": true,
     "points": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "bk_rating = combine(books, ratings)\n",
    "assert_equal(bk_rating['Book-Title'].value_counts().head().tolist(),[1088, 548, 407, 361, 349])\n",
    "assert_equal(list(bk_rating), ['ISBN','Book-Title', 'Book-Author',\\\n",
    "                               'Year-Of-Publication', 'Publisher',\\\n",
    "                               'Image-URL-S', 'Image-URL-M', 'Image-URL-L',\\\n",
    "                               'User-ID', 'Book-Rating'])\n",
    "assert_equal(bk_rating['Book-Title'].value_counts().head().index.tolist(),\\\n",
    "             ['Wild Animus', 'The Lovely Bones: A Novel', 'The Da Vinci Code',\\\n",
    "              'A Painted House', 'The Nanny Diaries: A Novel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Table\n",
    "Now that we have our books-ratings dataframe, we now need to create a pivot table which will allow us to compare users' recommendations so that we might find book recommendations.  In order to create a manageable pivot table, we will limit our list of books to only those with 150 ratings or more. We will say that if a book was given a rating of over 5, then the rating is favorable, but if it is 5 or less, then the rating should be considered unfavorable.  Favorable ratings will be assigned the value of one. Additionally, your function should allow you to assign unfavorable ratings the value of either zero or negative one.  For example, if zeroto1 is True, then you should scale your ratings from 0 to 1; however if it is False, then you should scale your ratings to -1 to 1   You will then return a numpy array that will serve as the comparison array for the recommender system below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d6d4f595565dce41e853c27e778b02a7",
     "grade": false,
     "grade_id": "pivot",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def pivot(rtngs, rating_count = 150, zeroto1=True):\n",
    "    '''\n",
    "    Takes the ratings dataframe and reduces it by removing books with less than the rating_count.\n",
    "    It then makes a pivot table containing ratings indexed by user id and ISBN, which is returned.  Finally, the ratings are\n",
    "    then converted into a matrix of 0 and 1 or -1 and 1, depending on the value of zeroto1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rtgs: A pandas.Dataframe\n",
    "    rating_count: An integer\n",
    "    zeroto1: A Boolean\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A Numpy array and a Pandas Dataframe\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    # Make a new Data structure that holds the book and the number of ratings\n",
    "    tmp = ratings.groupby('ISBN').size()\n",
    "    indexlist = tmp[tmp > 150].index.tolist()\n",
    "    tmp_df = ratings[ratings['ISBN'].isin(indexlist)]\n",
    "    \n",
    "    # rating matrix\n",
    "    pivot_df = tmp_df.pivot(index = 'User-ID', columns = 'ISBN', values = 'Book-Rating')\n",
    "    \n",
    "    if zeroto1 == True:\n",
    "        ratings_matrix = pivot_df.applymap(lambda x: 1 if x > 5 else 0).as_matrix()\n",
    "    else:\n",
    "        ratings_matrix = pivot_df.applymap(lambda x: 1 if x > 5 else -1).as_matrix()\n",
    "    \n",
    "    return ratings_matrix, pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e97fcad881c32ca651210bb043b7e88f",
     "grade": true,
     "grade_id": "pivot_test",
     "locked": true,
     "points": 13,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "zero_ratings_matrix, pivot_df_zero = pivot(ratings)\n",
    "assert_equal(type(np.array([])), type(zero_ratings_matrix))\n",
    "assert_equal(1, np.max(zero_ratings_matrix))\n",
    "assert_equal(0, np.min(zero_ratings_matrix))\n",
    "assert_equal((6393, 64), zero_ratings_matrix.shape)\n",
    "\n",
    "ratings_matrix, pivot_df = pivot(ratings, zeroto1=False)\n",
    "assert_equal(1, np.max(ratings_matrix))\n",
    "assert_equal(-1, np.min(ratings_matrix))\n",
    "assert_equal((6393, 64), ratings_matrix.shape)\n",
    "assert_equal(type(np.array([])), type(ratings_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we get to the actual recommendations, we will rely heavily the cosine_similarity in order to make our preditions.  The code for it is below and does not need modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    return(np.dot(u, v)/np.sqrt((np.dot(u, u) * np.dot(v, v))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I have made a user which is guaranteed to have a match in the ratings matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = ratings_matrix\n",
    "y = np.zeros(ratings_matrix.shape[1], dtype= np.int32)\n",
    "book = np.where(x[200,:] == 1)[0]\n",
    "y[4] = 1\n",
    "y[36] = 1\n",
    "y[44] = 1\n",
    "y[30] = -1\n",
    "y[20] = 1\n",
    "\n",
    "pivot_df.tmp_idx = np.array(range(x.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single user Recommendations\n",
    "Finally, let us find recommendations for a single user given our new user.  In this function, we will find the index of the existing user with the most similar likes and dislikes, as well as the cosine similarity between this existing user and the new user, y.  You should use cosine_similarity to find the most similar existing user.  Additionally, you should be outputting the mask array, which will help us later in finding the books that should be recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "8a91296e0964f7ea87c3406f820ac681",
     "grade": false,
     "grade_id": "similar_user",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def similar_user(x, y):\n",
    "    '''\n",
    "    Takes the array of user ratings as well as a new user and outputs the most similar user's\n",
    "    index in the x array which can be used to find the userID of the most similar user. Should\n",
    "    also output the cosine_similarity of the new user and the most similar user, as well as the \n",
    "    mask array.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: Numpy array\n",
    "    y: Numpy array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    idx: integer\n",
    "    cos: float\n",
    "    bk_vec: Numpy array\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # Compute similarity, find maximum value\n",
    "    sims = np.apply_along_axis(cosine_similarity, 1, x, y)\n",
    "    mx = np.nanmax(sims)\n",
    "\n",
    "    # Find the best matching user\n",
    "    idx = np.where(sims == mx)[0][0]\n",
    "    \n",
    "    # similarity\n",
    "    cos = cosine_similarity(y, x[idx])\n",
    "    \n",
    "    # mask array\n",
    "    # (any negative value is a movie to recommend)\n",
    "    bk_vec = y - x[idx]\n",
    "\n",
    "    # We want a mask aray, so we zero out any recommended movie.\n",
    "    bk_vec[bk_vec >= 0] = 1\n",
    "    bk_vec[bk_vec < 0] = 0\n",
    "    \n",
    "    return idx, cos, bk_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d2ed8c295fcb7e650d3e01fe41320080",
     "grade": true,
     "grade_id": "sim_user_test",
     "locked": true,
     "points": 14,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "id, cos, bk_vec = similar_user(x, y)\n",
    "assert_equal(64, len(bk_vec))\n",
    "assert_almost_equal(0.167705098312, cos)\n",
    "assert_equal(11676, pivot_df[pivot_df.tmp_idx == id].index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bk_ids = pivot_df[pivot_df.tmp_idx == id].columns\n",
    "# Now make a masked array to find movies to recommend\n",
    "# values are the movie ids, mask is the movies the most\n",
    "# similar user liked.\n",
    "\n",
    "ma_bk_idx = ma.array(bk_ids, mask = bk_vec)\n",
    "bk_idx = ma_bk_idx[~ma_bk_idx.mask] \n",
    "bk_df = books.ix[books.ISBN.isin(bk_idx)].dropna()\n",
    "bk_df['Book-Title'].tolist()[23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of Recommendations\n",
    "Now that we have created all of this frame work, we need to finally find the list of recommended books for the books with ratings that ranged from -1 to 1.  You should do this with the assistance of your masked array, your pivot dataframe, your books dataframe and the index of the most similar user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "bd8bf7c465e083eed3b539168ec7014f",
     "grade": false,
     "grade_id": "find_books",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_books(pivot_df, idx, books, bk_vec):\n",
    "    '''\n",
    "    Uses the inputs to create a list of books that are recommended to the new user.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pivot_df: A pandas Dataframe\n",
    "    idx: An integer\n",
    "    books: A pandas Dataframe\n",
    "    bk_vec: A numpy Array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bk_ls: A list\n",
    "    \n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    # Get the columns for the current user\n",
    "    bk_ids = pivot_df[pivot_df.tmp_idx == idx].columns\n",
    "    \n",
    "    # Now make a masked array to find books to recommend\n",
    "    # values are the ISBN, mask is the books the most similar user liked\n",
    "\n",
    "    ma_bk_idx = ma.array(bk_ids, mask = bk_vec)\n",
    "    bk_idx = ma_bk_idx[~ma_bk_idx.mask] \n",
    "    bk_df = books.ix[books.ISBN.isin(bk_idx)].dropna()\n",
    "    \n",
    "    # convert to list\n",
    "    bk_ls = bk_df['Book-Title'].tolist()\n",
    "    \n",
    "    return bk_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "fca363ba051f006acc5cf40baa7a4552",
     "grade": true,
     "grade_id": "list_check",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "book_list = find_books(pivot_df, id, books, bk_vec)\n",
    "assert_equal(33, len(book_list))\n",
    "assert_equal(\"Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))\", book_list[23])\n",
    "assert_equal('Confessions of a Shopaholic (Summer Display Opportunity)', book_list[15])\n",
    "assert_equal(['The Testament', 'Wild Animus', 'The Street Lawyer', 'The Five People You Meet in Heaven', 'A Painted House', 'The Perfect Storm : A True Story of Men Against the Sea', 'Empire Falls', 'The Red Tent (Bestselling Backlist)', 'The Nanny Diaries: A Novel', 'Life of Pi', \"Where the Heart Is (Oprah's Book Club (Paperback))\", 'The Da Vinci Code', 'Me Talk Pretty One Day', 'SHIPPING NEWS', 'Jurassic Park', 'Confessions of a Shopaholic (Summer Display Opportunity)', 'A Prayer for Owen Meany', 'Good in Bed', 'Summer Sisters', 'The Reader', 'The Brethren', '1st to Die: A Novel', 'Snow Falling on Cedars', \"Harry Potter and the Sorcerer's Stone (Harry Potter (Paperback))\", \"Tuesdays with Morrie: An Old Man, a Young Man, and Life's Greatest Lesson\", 'Interview with the Vampire', 'The Notebook', 'The Nanny Diaries: A Novel', 'Midwives: A Novel', 'The Divine Secrets of the Ya-Ya Sisterhood: A Novel', 'Harry Potter and the Chamber of Secrets (Book 2)', 'The Bridges of Madison County', 'House of Sand and Fog'], book_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
