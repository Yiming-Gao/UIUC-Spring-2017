{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not using the `Assignments` tab on the course JupyterHub server to read this notebook, read [Activating the assignments tab](https://github.com/lcdm-uiuc/info490-sp17/blob/master/help/act_assign_tab.md).\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_  â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded.\n",
    "\n",
    "# Problem 8.1: Social Media, Email.\n",
    "\n",
    "For this problem, we will be doing basic analysis and data extraction on emails located in our data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2395bad6e6f75d4a6ff5764853af96f5",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import email as em\n",
    "from email import policy\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_instance, assert_true\n",
    "from numpy.testing import assert_array_equal, assert_almost_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get email info\n",
    "In this function, you will write a function to do the following things:\n",
    "- Open an email, given a datapath\n",
    "- Return who the message was to, who it was from, and the subject line.\n",
    "- If \"key\" is true, then also return a list of keys. If \"key\" is false, an empty list is returned instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "90cebdd34ec8d4a6521e5e50328155cf",
     "grade": false,
     "grade_id": "combine",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def email_info(datapath, key=False):\n",
    "    '''\n",
    "    Extracts the \"To\", \"From\" and \"Subject\" information from a given email.\n",
    "    Also returns either a list of header keys or an empty list, depending on the\n",
    "    value of \"key\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datapath: A string\n",
    "    key: A boolean\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tofromsub = a list of strings\n",
    "    headkey = a list of strings or an empty list\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    with open(datapath, 'r') as fin:\n",
    "        msg = em.message_from_file(fin, policy = policy.default)\n",
    "    \n",
    "    tofromsub = [msg['to'], msg['from'], msg['subject']]\n",
    "    \n",
    "    if (key == True):\n",
    "        headkey = msg.keys()\n",
    "    else:\n",
    "        headkey = []\n",
    "    \n",
    "    return tofromsub, headkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "18b0cb291275edce63599ea4855ff3a9",
     "grade": true,
     "grade_id": "combine_test",
     "locked": true,
     "points": 13,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "dat1 = '/home/data_scientist/data/email/ham/00001.1a31cc283af0060967a233d26548a6ce'\n",
    "emailhead1, headkey1 = email_info(dat1)\n",
    "assert_is_instance(emailhead1, list)\n",
    "assert_is_instance(headkey1, list)\n",
    "assert_equal(headkey1, [])\n",
    "assert_equal(emailhead1, ['Chris Garrigues <cwg-dated-1030314468.7c7c85@DeepEddy.Com>', 'Robert Elz <kre@munnari.OZ.AU>', 'Re: New Sequences Window'])\n",
    "assert_equal(len(headkey1), 0)\n",
    "assert_equal(len(emailhead1), 3)\n",
    "\n",
    "dat2 = '/home/data_scientist/data/email/spam/00001.317e78fa8ee2f54cd4890fdc09ba8176'\n",
    "emailhead2, headkey2 = email_info(dat2, key = True)\n",
    "assert_is_instance(emailhead2, list)\n",
    "assert_is_instance(headkey2, list)\n",
    "assert_equal(headkey2, ['Return-Path', 'Delivered-To' , 'Received', 'Received',\\\n",
    "                        'Received', 'Received', 'Received', \\\n",
    "                        'X-Authentication-Warning', 'Received', 'Message-Id',\\\n",
    "                        'Date', 'To', 'From', 'MIME-Version', 'Content-Type',\\\n",
    "                        'Subject', 'Sender', 'Errors-To', 'X-Mailman-Version',\\\n",
    "                        'Precedence', 'List-Id', 'X-Beenthere'])\n",
    "assert_equal(emailhead2, ['ilug@linux.ie', 'Start Now <startnow2002@hotmail.com>', '[ILUG] STOP THE MLM INSANITY'])\n",
    "assert_equal(len(headkey2), 22)\n",
    "assert_equal(len(emailhead2), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many Payloads\n",
    "Now, we want to grab many emails from the same directory so that we can perform analysis and training on them later. This function should take four arguments: a string called \"path\" that states the base directory that you want to extract all of your payloads from, two integers, stating on which number message to start and stop at, inclusive, and a boolean that states if you want to look at ham or spam.  You should use os.walk(). For example, if beg = 50 and end = 75, you should iterate through the 50th message through the 75th, inclusive. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9587bdb86e309b765ee6375f9d01f9a8",
     "grade": false,
     "grade_id": "pivot",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def many_payloads(path, beg, end, ham = True):\n",
    "    '''\n",
    "    Captures the payloads of the emails specified between beg and end,\n",
    "    and appends the payloads into a list called payloads.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: A string\n",
    "    beg: An integer\n",
    "    end: An integer\n",
    "    ham: A boolean\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    payloads: A list of strings.\n",
    "    '''\n",
    "    # Note: We cannot name it as ham since ham is a local variable!\n",
    "    ham_result = []\n",
    "    spam_result = []\n",
    "    mypath = path + '/'\n",
    "\n",
    "    # Read in good (ham) emails\n",
    "    for root, dirs, files in os.walk(os.path.join(mypath, 'ham')):\n",
    "        for file in files[beg : end + 1]:\n",
    "\n",
    "            with open(os.path.join(root, file), encoding = 'ISO-8859-1') as fin:\n",
    "                msg = em.message_from_file(fin, policy = policy.default)\n",
    "                for part in msg.walk():\n",
    "                    if part.get_content_type() == 'text/plain':\n",
    "                        data = part.get_payload(None, decode = True)\n",
    "\n",
    "                ham_result.append(data.decode(encoding = 'ISO-8859-1'))\n",
    "\n",
    "    # Read in bad (spam) emails\n",
    "    for root, dirs, files in os.walk(os.path.join(mypath, 'spam')):\n",
    "        for file in files[beg : end + 1]:\n",
    "                \n",
    "            with open(os.path.join(root, file), encoding = 'ISO-8859-1') as fin:\n",
    "                msg = em.message_from_file(fin, policy = policy.default)\n",
    "                for part in msg.walk():\n",
    "                    if part.get_content_type() == 'text/plain':\n",
    "                        data = part.get_payload(None, decode = True)\n",
    "\n",
    "                spam_result.append(data.decode(encoding='ISO-8859-1'))\n",
    "                \n",
    "    if (ham == True):\n",
    "        payloads = ham_result\n",
    "    else:\n",
    "        payloads = spam_result\n",
    "        \n",
    "    return payloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6053cd543a7e27d5c45b9a68880e87cd",
     "grade": true,
     "grade_id": "pivot_test",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ham = many_payloads('/home/data_scientist/data/email', 100, 600, ham = True)\n",
    "assert_is_instance(ham, list)\n",
    "assert_true(all(isinstance(h, str) for h in ham))\n",
    "assert_equal(len(ham), 501)\n",
    "assert_true(ham[7].startswith(\"I've got some really interesting wav files here.\"))\n",
    "assert_true(ham[53].startswith('On Tue, Jul 30, 2002 at 11:28:11AM +0200, David Neary mentioned:'))\n",
    "\n",
    "spam = many_payloads('/home/data_scientist/data/email', 100, 600, ham = False)\n",
    "assert_is_instance(spam, list)\n",
    "assert_true(all(isinstance(s, str) for s in spam))\n",
    "assert_equal(len(spam), 501)\n",
    "assert_true(spam[365].startswith(\"1916eEph3-937NQem2852GQnA3-l25\"))\n",
    "assert_true(spam[-1].startswith('Your mortgage has been approved.'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to arrays\n",
    "In order to use scikit learn, we need to convert our ham and spam arrays to numpy arrays (pos_emails and neg_emails), and then create label arrays for each previous list (spam or ham) where the ham label array (pos_labels) should be filled with ones and be the length of pos_emails, and the spam label array (neg_labels) should be filled with zeros and be the length of the neg_emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e821c489f22d09742fe2358db18014ac",
     "grade": false,
     "grade_id": "similar_user",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def to_arrays(ham, spam):\n",
    "    '''\n",
    "    Converts ham and spam to arrays, and also creates two label arrays:\n",
    "    one filled with zeros for spam and one filled with ones for ham. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    spam: A list of strings\n",
    "    ham: A list of strings\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of four arrays\n",
    "    '''\n",
    "    \n",
    "     # YOUR CODE HERE\n",
    "    pos_emails = np.array(ham)\n",
    "    neg_emails = np.array(spam) \n",
    "\n",
    "    # Create label arrays\n",
    "    pos_labels = np.ones(pos_emails.shape[0])\n",
    "    neg_labels = np.zeros(neg_emails.shape[0])\n",
    "    \n",
    "    return pos_emails, neg_emails, pos_labels, neg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4ea5600d81a3d5aa4a304f7c6ef68390",
     "grade": true,
     "grade_id": "sim_user_test",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pos_emails, neg_emails, pos_labels, neg_labels = to_arrays(ham, spam)\n",
    "\n",
    "assert_is_instance(pos_emails, np.ndarray)\n",
    "assert_is_instance(neg_emails, np.ndarray)\n",
    "assert_is_instance(pos_labels, np.ndarray)\n",
    "assert_is_instance(neg_labels, np.ndarray)\n",
    "\n",
    "assert_array_equal(pos_emails, ham)\n",
    "assert_array_equal(neg_emails, spam)\n",
    "\n",
    "assert_array_equal(pos_labels, [1] * len(ham))\n",
    "assert_array_equal(neg_labels, [0] * len(spam))\n",
    "\n",
    "assert_true(pos_emails[0].startswith(\"Use the GUI and don't delete files, use the other option, whats it called\"))\n",
    "assert_true(neg_emails[60].startswith(\"RECIEVE ALL CHANNELS ON YOUR SATELLITE SYSTEM! 1-888-406-4246\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Freeing up some memory\n",
    "%xdel ham\n",
    "%xdel spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing sets\n",
    "In order to perform some analysis on this data, we need to split and then contatenate the pos_emails and neg_emails together (and do the same for the pos_labels and neg_labels) so as to create a training and testing array for both X and y.  The \"split\" variable will tell you where to split your arrays.  For example, If split is 300, the training set will consist of the first 300 emails in pos_emails plus the first 300 emails in neg_emails, and the rest of the emails go into the test set.  The same will be true for the label arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "9d7bb13d947842f3e402145a6799f754",
     "grade": false,
     "grade_id": "find_books",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def test_train(pos_emails, neg_emails, pos_labels, neg_labels, split):\n",
    "    '''\n",
    "    Splits the emails and labels into training and testing sets.    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pos_emails: A numpy array of strings\n",
    "    neg_emails: A numpy array of strings\n",
    "    pos_labels: A numpy array of ints or floats\n",
    "    neg_labels: A numpy array of ints or floats\n",
    "    split: an int \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of four numpy arrays: X_train, X_test, y_train, y_test.\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    X_train = np.concatenate((pos_emails[:split], \n",
    "                              neg_emails[:split]), axis = 0)\n",
    "\n",
    "    X_test = np.concatenate((pos_emails[split:],\n",
    "                             neg_emails[split:]), axis = 0)\n",
    "\n",
    "    y_train = np.concatenate((pos_labels[:split], \n",
    "                              neg_labels[:split]), axis = 0)\n",
    "\n",
    "    y_test = np.concatenate((pos_labels[split:],\n",
    "                             neg_labels[split:]), axis = 0)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "d767b94feace3a666901d95681fe9c09",
     "grade": true,
     "grade_id": "list_check",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = test_train(\n",
    "    pos_emails, neg_emails, pos_labels, neg_labels, split=400\n",
    "    )\n",
    "\n",
    "assert_is_instance(X_train, np.ndarray)\n",
    "assert_is_instance(X_test, np.ndarray)\n",
    "assert_is_instance(y_train, np.ndarray)\n",
    "assert_is_instance(y_test, np.ndarray)\n",
    "\n",
    "assert_array_equal(X_train[:400], pos_emails[:400])\n",
    "assert_array_equal(X_train[400:], neg_emails[:400])\n",
    "\n",
    "assert_array_equal(X_test[:len(pos_emails) - 400], pos_emails[400:])\n",
    "assert_array_equal(X_test[len(pos_emails) - 400:], neg_emails[400:])\n",
    "\n",
    "assert_array_equal(y_train[:400], pos_labels[:400])\n",
    "assert_array_equal(y_train[400:], neg_labels[:400])\n",
    "\n",
    "assert_array_equal(y_test[:len(pos_labels) - 400], pos_labels[400:])\n",
    "assert_array_equal(y_test[len(pos_labels) - 400:], neg_labels[400:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeing up some more memory\n",
    "%xdel pos_emails\n",
    "%xdel neg_emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spam classification\n",
    "\n",
    "Finally, we will use our training and testing sets to identify spam correctly.\n",
    "- Use unigrams and bigrams,\n",
    "- Build a pipeline by using TfidfVectorizer and LinearSVC,\n",
    "- Name the first step tf and the second step svc,\n",
    "- Use default parameters for both TfidfVectorizer and LinearSVC, and\n",
    "- Use English stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b93da9d20b9016db88b58dc26f3948db",
     "grade": false,
     "grade_id": "long_words",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_and_predict(X_train, y_train, X_test, random_state):\n",
    "    '''\n",
    "    Creates a document term matrix and uses SVM classifier to make document classifications.\n",
    "    Uses English stop words.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train: A list of strings.\n",
    "    y_train: A list of strings.\n",
    "    X_test: A list of strings.\n",
    "    random_state: A np.random.RandomState instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (clf, y_pred)\n",
    "    clf: A Pipeline instance.\n",
    "    y_pred: A numpy array.    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    tools = [('tf', TfidfVectorizer(stop_words = 'english', ngram_range = (1, 2))), \n",
    "             ('svc', LinearSVC(random_state = random_state))]\n",
    "    clf = Pipeline(tools)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)    \n",
    "    \n",
    "    return clf, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "aa81360b05d198e5cfe3020d0e8126cb",
     "grade": true,
     "grade_id": "long_words_test",
     "locked": true,
     "points": 8,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC prediction accuracy =  72.8%\n"
     ]
    }
   ],
   "source": [
    "clf, y_pred = fit_and_predict(X_train, y_train, X_test, random_state=check_random_state(0))\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"SVC prediction accuracy = {0:5.1f}%\".format(100.0 * score))\n",
    "\n",
    "assert_is_instance(clf, Pipeline)\n",
    "assert_is_instance(y_pred, np.ndarray)\n",
    "tf = clf.named_steps['tf']\n",
    "assert_is_instance(tf, TfidfVectorizer)\n",
    "assert_is_instance(clf.named_steps['svc'], LinearSVC)\n",
    "assert_equal(tf.ngram_range, (1, 2))\n",
    "assert_equal(tf.stop_words, 'english')\n",
    "assert_equal(len(y_pred), len(y_test))\n",
    "assert_array_equal(y_pred[:10], [1] * 10)\n",
    "assert_array_equal(y_pred[-10:], [0] * 10)\n",
    "assert_almost_equal(score, 0.7277227722772277)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
