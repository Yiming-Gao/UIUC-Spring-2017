{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "92f305b94c8cc1e3d3a098fd807fdfa5",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Week 2 Problem 3\n",
    "\n",
    "If you are not using the `Assignments` tab on the course JupyterHub server to read this notebook, read [Activating the assignments tab](https://github.com/lcdm-uiuc/info490-sp17/blob/master/help/act_assign_tab.md).\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_  â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Problem 2.3. Logistic Regression\n",
    "\n",
    "In this problem, we will fit a logistic regression model on day of the week and air carriers to predict whether a flight is delayed or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "4b1514db4e9a50fb1bf848b77b7d0e8c",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "    \n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from nose.tools import assert_equal\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal\n",
    "from pandas.util.testing import assert_frame_equal\n",
    "\n",
    "sns.set(style=\"white\", font_scale=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the columns `DayOfWeek` and `UniqueCarrier` as attributes and `DepDelay` as the target prediction. For simplicity, we will only use the flights that departed from O'Hare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "b8e26d3163c955e5a2514faa95fd07f3",
     "grade": false,
     "grade_id": "read_csv",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "filename = '/home/data_scientist/data/2001.csv'\n",
    "\n",
    "usecols = (3, 8, 15, 17)\n",
    "columns = ['DayOfWeek', 'UniqueCarrier', 'DepDelay', 'Origin']\n",
    "\n",
    "all_data = pd.read_csv(filename, header=0, na_values=['NA'], usecols=usecols, names=columns).dropna()\n",
    "\n",
    "local = all_data.loc[all_data['Origin'] == 'ORD'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print print out the first few columns.\n",
    "\n",
    "```python\n",
    ">>> print(local.head())\n",
    "```\n",
    "\n",
    "```\n",
    "      DayOfWeek UniqueCarrier  DepDelay Origin\n",
    "1855          2            US        -1    ORD\n",
    "1856          3            US        -4    ORD\n",
    "1857          4            US        -3    ORD\n",
    "1858          5            US        -3    ORD\n",
    "1859          6            US        -4    ORD\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "bbff04c484acca0872ce134a0479d5a6",
     "grade": false,
     "grade_id": "print_local_head",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DayOfWeek UniqueCarrier  DepDelay Origin\n",
      "1855          2            US      -1.0    ORD\n",
      "1856          3            US      -4.0    ORD\n",
      "1857          4            US      -3.0    ORD\n",
      "1858          5            US      -3.0    ORD\n",
      "1859          6            US      -4.0    ORD\n"
     ]
    }
   ],
   "source": [
    "print(local.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will using logistic regression on the `DayOfWeek` and `UniqueCarrier` columns to predict whether a flight is delayed or not. However, logistic regression is for predicting **binary** outcomes and `DepDelay` is not binary. So our first task will be to convert this column into binary numbers.\n",
    "\n",
    "## Convert DepDelay to binary\n",
    "\n",
    "- Write a function named `convert_to_binary()` that converts a specific column of a DataFrame into 0's or 1's using the `cutoff` parameter. See the function doctsring for more.\n",
    "- It actually does not matter whether 0's or 1's are integers or floats, but to pass assertion tests, make sure that your 0's and 1's are **integers** for all parts of this notebook unless otherwise required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "27595b5fcf50f34f1397fa2766873b2e",
     "grade": false,
     "grade_id": "convert_to_binary_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_binary(df, column, cutoff):\n",
    "    '''\n",
    "    Converts one column in Pandas.DataFrame \"df\" into binary\n",
    "    as a new column, and returns the new DataFrame (\"df\" plus new binary column).\n",
    "    Note that \"df\" should NOT be altered.\n",
    "    \n",
    "    The returned DataFrame has one more column than \"df\".\n",
    "    The name of this column is in the form \"column_binary\".\n",
    "    For example, if \"column\" is \"DepDelay\", the name of the extra column\n",
    "    in the returned DataFrame is \"DepDelay_binary\".\n",
    "    \n",
    "    We assume that df[column] contains only ints or floats.\n",
    "    If df[column] < cutoff, df[column_binary] is 0.\n",
    "    If df[column] >= cutoff, df[column_binary] is 1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A Pandas.DataFrame.\n",
    "    column: A string.\n",
    "    cutoff: An int.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A Pandas.DataFrame.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # Make a deep copy of df, refering to a new DataFrame\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Create a new column for the new DataFrame\n",
    "    result[column + '_binary'] = (result[column] >= cutoff).astype(int)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define a flight to be late if its departure delay is more than or equal to 5 minutes, and on-time if its departure delay is less than 5 minutes.\n",
    "\n",
    "```python\n",
    ">>> local = convert_to_binary(local, 'DepDelay', 5)\n",
    ">>> print(local.tail(10))\n",
    "```\n",
    "\n",
    "```\n",
    "         DayOfWeek UniqueCarrier  DepDelay Origin  DepDelay_binary\n",
    "5960735          6            DL         4    ORD                0\n",
    "5960736          7            DL         7    ORD                1\n",
    "5960737          1            DL        -2    ORD                0\n",
    "5960738          2            DL        -3    ORD                0\n",
    "5960739          3            DL         0    ORD                0\n",
    "5960740          4            DL        58    ORD                1\n",
    "5960741          5            DL         1    ORD                0\n",
    "5960742          6            DL         0    ORD                0\n",
    "5960743          7            DL        -8    ORD                0\n",
    "5960744          1            DL        -3    ORD                0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "47be0bfab219d96faf8c7c929578d2c3",
     "grade": false,
     "grade_id": "print_local_tail",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         DayOfWeek UniqueCarrier  DepDelay Origin  DepDelay_binary\n",
      "5960735          6            DL       4.0    ORD                0\n",
      "5960736          7            DL       7.0    ORD                1\n",
      "5960737          1            DL      -2.0    ORD                0\n",
      "5960738          2            DL      -3.0    ORD                0\n",
      "5960739          3            DL       0.0    ORD                0\n",
      "5960740          4            DL      58.0    ORD                1\n",
      "5960741          5            DL       1.0    ORD                0\n",
      "5960742          6            DL       0.0    ORD                0\n",
      "5960743          7            DL      -8.0    ORD                0\n",
      "5960744          1            DL      -3.0    ORD                0\n"
     ]
    }
   ],
   "source": [
    "local = convert_to_binary(local, 'DepDelay', 5)\n",
    "print(local.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use some simple unit tests to see if the function works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "592e9639215b740eb31a423e9f502767",
     "grade": true,
     "grade_id": "convert_to_binary_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame({\n",
    "    'a': list(range(-5, 5)),\n",
    "    'b': list(range(10))\n",
    "    })\n",
    "\n",
    "test1 = convert_to_binary(df0, 'a', 0)\n",
    "answer1 = df0.join(pd.DataFrame({'a_binary': [0] * 5 + [1] * 5}))\n",
    "assert_frame_equal(test1, answer1)\n",
    "\n",
    "test2 = convert_to_binary(df0, 'b', 4)\n",
    "answer2 = df0.join(pd.DataFrame({'b_binary': [0] * 4 + [1] * 6}))\n",
    "assert_frame_equal(test2, answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert categorical variables to dummy indicator variables\n",
    "\n",
    "`DayOfWeek` and `UniqueCarrier` are categorical variables, while we need binary indicator variables to perform logistic regression.\n",
    "\n",
    "- Use [pandas.get_dummies()](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html) to write a function named `convert_to_dummy()` that transforms categorical variables into binary indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5f568ba56f9f1b8da55806dbade9e377",
     "grade": false,
     "grade_id": "convert_to_dummy_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_dummy(df, dummy_columns, keep_columns):\n",
    "    '''\n",
    "    Transforms categorical variables of dummy_columns into binary indicator variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A pandas.DataFrame\n",
    "    dummy_columns: A list of strings. Columns of df that are converted to dummies.\n",
    "    keep_columns: A list of strings. Columns of df that are kept in the result.\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pandas.DataFrame\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # Keep some columns\n",
    "    result1 = df[keep_columns]\n",
    "    \n",
    "    # Convert to dummy variables\n",
    "    result2 = pd.get_dummies(df[dummy_columns], columns = dummy_columns).astype(int)\n",
    "    \n",
    "    # Join two parts\n",
    "    result = result1.join(result2)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should have only binary indicators in all columns.\n",
    "\n",
    "```python\n",
    ">>> data = add_dummy(local, add_columns=['DayOfWeek', 'UniqueCarrier'], keep_columns=['DepDelay_binary'])\n",
    ">>> print(data.head())\n",
    "```\n",
    "\n",
    "```\n",
    "      DepDelay_binary  DayOfWeek_1  DayOfWeek_2  DayOfWeek_3  DayOfWeek_4  \\\n",
    "1855                0            0            1            0            0   \n",
    "1856                0            0            0            1            0   \n",
    "1857                0            0            0            0            1   \n",
    "1858                0            0            0            0            0   \n",
    "1859                0            0            0            0            0   \n",
    "\n",
    "      DayOfWeek_5  DayOfWeek_6  DayOfWeek_7  UniqueCarrier_AA  \\\n",
    "1855            0            0            0                 0   \n",
    "1856            0            0            0                 0   \n",
    "1857            0            0            0                 0   \n",
    "1858            1            0            0                 0   \n",
    "1859            0            1            0                 0   \n",
    "\n",
    "      UniqueCarrier_AS  UniqueCarrier_CO  UniqueCarrier_DL  UniqueCarrier_HP  \\\n",
    "1855                 0                 0                 0                 0   \n",
    "1856                 0                 0                 0                 0   \n",
    "1857                 0                 0                 0                 0   \n",
    "1858                 0                 0                 0                 0   \n",
    "1859                 0                 0                 0                 0   \n",
    "\n",
    "      UniqueCarrier_MQ  UniqueCarrier_NW  UniqueCarrier_TW  UniqueCarrier_UA  \\\n",
    "1855                 0                 0                 0                 0   \n",
    "1856                 0                 0                 0                 0   \n",
    "1857                 0                 0                 0                 0   \n",
    "1858                 0                 0                 0                 0   \n",
    "1859                 0                 0                 0                 0   \n",
    "\n",
    "      UniqueCarrier_US  \n",
    "1855                 1  \n",
    "1856                 1  \n",
    "1857                 1  \n",
    "1858                 1  \n",
    "1859                 1  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "909d85bedc8c1c17fabdaf3110f6b211",
     "grade": false,
     "grade_id": "print_data_head",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DepDelay_binary  DayOfWeek_1  DayOfWeek_2  DayOfWeek_3  DayOfWeek_4  \\\n",
      "1855                0            0            1            0            0   \n",
      "1856                0            0            0            1            0   \n",
      "1857                0            0            0            0            1   \n",
      "1858                0            0            0            0            0   \n",
      "1859                0            0            0            0            0   \n",
      "\n",
      "      DayOfWeek_5  DayOfWeek_6  DayOfWeek_7  UniqueCarrier_AA  \\\n",
      "1855            0            0            0                 0   \n",
      "1856            0            0            0                 0   \n",
      "1857            0            0            0                 0   \n",
      "1858            1            0            0                 0   \n",
      "1859            0            1            0                 0   \n",
      "\n",
      "      UniqueCarrier_AS  UniqueCarrier_CO  UniqueCarrier_DL  UniqueCarrier_HP  \\\n",
      "1855                 0                 0                 0                 0   \n",
      "1856                 0                 0                 0                 0   \n",
      "1857                 0                 0                 0                 0   \n",
      "1858                 0                 0                 0                 0   \n",
      "1859                 0                 0                 0                 0   \n",
      "\n",
      "      UniqueCarrier_MQ  UniqueCarrier_NW  UniqueCarrier_TW  UniqueCarrier_UA  \\\n",
      "1855                 0                 0                 0                 0   \n",
      "1856                 0                 0                 0                 0   \n",
      "1857                 0                 0                 0                 0   \n",
      "1858                 0                 0                 0                 0   \n",
      "1859                 0                 0                 0                 0   \n",
      "\n",
      "      UniqueCarrier_US  \n",
      "1855                 1  \n",
      "1856                 1  \n",
      "1857                 1  \n",
      "1858                 1  \n",
      "1859                 1  \n"
     ]
    }
   ],
   "source": [
    "data = convert_to_dummy(local, dummy_columns=['DayOfWeek', 'UniqueCarrier'], keep_columns=['DepDelay_binary'])\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b8ae2c32636cd4f8a2fe3a3715b5e5f6",
     "grade": true,
     "grade_id": "convert_to_dummy_test",
     "locked": true,
     "points": 20,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame({\n",
    "    'a': ['a'] * 3,\n",
    "    'b': [1] * 3,\n",
    "    'c': [c for c in 'abc'],\n",
    "    'd': list(range(3))\n",
    "    })\n",
    "\n",
    "test1 = convert_to_dummy(df0, dummy_columns=['c'], keep_columns=['a'])\n",
    "answer1 = pd.DataFrame({\n",
    "    'a': ['a'] * 3,\n",
    "    'c_a': [1, 0, 0], 'c_b': [0, 1, 0], 'c_c': [0, 0, 1]\n",
    "    })\n",
    "assert_frame_equal(test1, answer1)\n",
    "\n",
    "test2 = convert_to_dummy(df0, dummy_columns=['c', 'd'], keep_columns=['b'])\n",
    "answer2 = pd.DataFrame({\n",
    "    'b': [1] * 3,\n",
    "    'c_a': [1, 0, 0], 'c_b': [0, 1, 0], 'c_c': [0, 0, 1],\n",
    "    'd_0': [1, 0, 0], 'd_1': [0, 1, 0], 'd_2': [0, 0, 1]\n",
    "    })\n",
    "\n",
    "assert_frame_equal(test2, answer2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add intercept\n",
    "\n",
    "The [Logit()](http://statsmodels.sourceforge.net/0.6.0/generated/statsmodels.discrete.discrete_model.Logit.html) function doesn't include intercept by default and we have to manualy add the intercept.\n",
    "\n",
    "- Write a function named `add_intercept()` that adds an extra column named `Intercept` with all 1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "83757f17a8bf8e41dce2ee808cd8ee2b",
     "grade": false,
     "grade_id": "add_intercept_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def add_intercept(df):\n",
    "    '''\n",
    "    Appends to \"df\" an \"Intercept\" column whose values are all 1.0.\n",
    "    Note that \"df\" should NOT be altered.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A pandas.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pandas.DataFrame\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # Make a deep copy, refering to a new DataFrame\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Note that result = df means result and df refer to the same object!\n",
    "    # Add Intercept column\n",
    "    result['Intercept'] = 1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if there is now an `Intercept` column.\n",
    "\n",
    "```python\n",
    ">>> data = add_intercept(data)\n",
    ">>> print(data['Intercept'].head())\n",
    "```\n",
    "\n",
    "```\n",
    "1855    1\n",
    "1856    1\n",
    "1857    1\n",
    "1858    1\n",
    "1859    1\n",
    "Name: Intercept, dtype: int64\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9242f3c5c7e6caeee612a78ed6626ebb",
     "grade": false,
     "grade_id": "print_intercept_head",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1855    1\n",
      "1856    1\n",
      "1857    1\n",
      "1858    1\n",
      "1859    1\n",
      "Name: Intercept, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = add_intercept(data)\n",
    "print(data['Intercept'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4b1d018af0b6dccdf47623a2acd89bcb",
     "grade": true,
     "grade_id": "add_intercept_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame({'a': [c for c in 'abcde']})\n",
    "\n",
    "test1 = add_intercept(df0)\n",
    "answer1 = df0.join(pd.DataFrame({'Intercept': [1] * 5}))\n",
    "\n",
    "assert_frame_equal(test1, answer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: fit\\_logistic()\n",
    "\n",
    "- Use statsmodels [Logit()](http://blog.yhat.com/posts/logistic-regression-and-python.html) to fit a logistic regression model to the columns in `train_columns`. Use (non-regularized) maximum likelihood with the default parameters (no optional parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "2855ba7496ef507b140d3e2b9fa59174",
     "grade": false,
     "grade_id": "fit_logistic_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_logitistic(df, train_columns, test_column):\n",
    "    '''\n",
    "    Fits a logistic regression model on \"train_columns\" to predict \"test_column\".\n",
    "    \n",
    "    The function returns a tuple of (model ,result).\n",
    "    \"model\" is an instance of Logit(). \"result\" is the result of Logit.fit() method.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_columns: A list of strings\n",
    "    test_column: A string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tuple of (model, result)\n",
    "    model: An object of type statsmodels.discrete.discrete_model.Logit\n",
    "    result: An object of type statsmodels.discrete.discrete_model.BinaryResultsWrapper\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # Create the model\n",
    "    model = sm.Logit(df[test_column], df[train_columns])\n",
    "\n",
    "    # Fit the model\n",
    "    result = model.fit()\n",
    "    \n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we exclude `DayOfWeek_1` and `UniqueCarrier_AA` from our fit to prevent [multicollinearity](https://en.wikipedia.org/wiki/Multicollinearity#Remedies_for_multicollinearity).\n",
    "\n",
    "```python\n",
    ">>> model, result = fit_logitistic(data, train_columns=train_columns, test_column='DepDelay_binary')\n",
    "```\n",
    "\n",
    "```\n",
    "Optimization terminated successfully.\n",
    "         Current function value: 0.589094\n",
    "         Iterations 5\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> print(result.summary())\n",
    "```\n",
    "\n",
    "```\n",
    "                           Logit Regression Results                           \n",
    "==============================================================================\n",
    "Dep. Variable:        DepDelay_binary   No. Observations:               321227\n",
    "Model:                          Logit   Df Residuals:                   321211\n",
    "Method:                           MLE   Df Model:                           15\n",
    "Date:                Thu, 21 Jan 2016   Pseudo R-squ.:                0.005735\n",
    "Time:                        22:05:38   Log-Likelihood:            -1.8923e+05\n",
    "converged:                       True   LL-Null:                   -1.9032e+05\n",
    "                                        LLR p-value:                     0.000\n",
    "====================================================================================\n",
    "                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
    "------------------------------------------------------------------------------------\n",
    "DayOfWeek_2         -0.1574      0.015    -10.479      0.000        -0.187    -0.128\n",
    "DayOfWeek_3          0.0164      0.015      1.113      0.266        -0.012     0.045\n",
    "DayOfWeek_4          0.2148      0.014     14.911      0.000         0.187     0.243\n",
    "DayOfWeek_5          0.2059      0.014     14.274      0.000         0.178     0.234\n",
    "DayOfWeek_6          0.0229      0.015      1.514      0.130        -0.007     0.053\n",
    "DayOfWeek_7          0.1085      0.015      7.397      0.000         0.080     0.137\n",
    "UniqueCarrier_AS    -0.3596      0.134     -2.679      0.007        -0.623    -0.096\n",
    "UniqueCarrier_CO    -0.0101      0.030     -0.339      0.735        -0.069     0.048\n",
    "UniqueCarrier_DL     0.5507      0.024     22.889      0.000         0.504     0.598\n",
    "UniqueCarrier_HP     0.8619      0.039     22.121      0.000         0.786     0.938\n",
    "UniqueCarrier_MQ     0.0906      0.012      7.502      0.000         0.067     0.114\n",
    "UniqueCarrier_NW     0.2597      0.025     10.572      0.000         0.212     0.308\n",
    "UniqueCarrier_TW     0.3749      0.036     10.343      0.000         0.304     0.446\n",
    "UniqueCarrier_UA     0.1901      0.010     19.987      0.000         0.172     0.209\n",
    "UniqueCarrier_US     0.2573      0.027      9.632      0.000         0.205     0.310\n",
    "Intercept           -1.1426      0.012    -94.960      0.000        -1.166    -1.119\n",
    "====================================================================================\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a8fecbebbfb116f413be9df92942fd07",
     "grade": false,
     "grade_id": "fit_logistic_columns",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.589094\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "train_columns = [ ### 'DayofWeek_1' # do not include this\n",
    "        'DayOfWeek_2', 'DayOfWeek_3', 'DayOfWeek_4',\n",
    "        'DayOfWeek_5', 'DayOfWeek_6', 'DayOfWeek_7',\n",
    "        ### 'UniqueCarrierAA' # do not include this\n",
    "        'UniqueCarrier_AS', 'UniqueCarrier_CO', 'UniqueCarrier_DL',\n",
    "        'UniqueCarrier_HP', 'UniqueCarrier_MQ', 'UniqueCarrier_NW',\n",
    "        'UniqueCarrier_TW', 'UniqueCarrier_UA', 'UniqueCarrier_US',\n",
    "        'Intercept'\n",
    "        ]\n",
    "\n",
    "model, result = fit_logitistic(data, train_columns=train_columns, test_column='DepDelay_binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "dd63a296a0f8587184c324b995d0c462",
     "grade": false,
     "grade_id": "print_result_summary",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:        DepDelay_binary   No. Observations:               321227\n",
      "Model:                          Logit   Df Residuals:                   321211\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Sun, 29 Jan 2017   Pseudo R-squ.:                0.005735\n",
      "Time:                        15:18:22   Log-Likelihood:            -1.8923e+05\n",
      "converged:                       True   LL-Null:                   -1.9032e+05\n",
      "                                        LLR p-value:                     0.000\n",
      "====================================================================================\n",
      "                       coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------------\n",
      "DayOfWeek_2         -0.1574      0.015    -10.479      0.000        -0.187    -0.128\n",
      "DayOfWeek_3          0.0164      0.015      1.113      0.266        -0.012     0.045\n",
      "DayOfWeek_4          0.2148      0.014     14.911      0.000         0.187     0.243\n",
      "DayOfWeek_5          0.2059      0.014     14.274      0.000         0.178     0.234\n",
      "DayOfWeek_6          0.0229      0.015      1.514      0.130        -0.007     0.053\n",
      "DayOfWeek_7          0.1085      0.015      7.397      0.000         0.080     0.137\n",
      "UniqueCarrier_AS    -0.3596      0.134     -2.679      0.007        -0.623    -0.096\n",
      "UniqueCarrier_CO    -0.0101      0.030     -0.339      0.735        -0.069     0.048\n",
      "UniqueCarrier_DL     0.5507      0.024     22.889      0.000         0.504     0.598\n",
      "UniqueCarrier_HP     0.8619      0.039     22.121      0.000         0.786     0.938\n",
      "UniqueCarrier_MQ     0.0906      0.012      7.502      0.000         0.067     0.114\n",
      "UniqueCarrier_NW     0.2597      0.025     10.572      0.000         0.212     0.308\n",
      "UniqueCarrier_TW     0.3749      0.036     10.343      0.000         0.304     0.446\n",
      "UniqueCarrier_UA     0.1901      0.010     19.987      0.000         0.172     0.209\n",
      "UniqueCarrier_US     0.2573      0.027      9.632      0.000         0.205     0.310\n",
      "Intercept           -1.1426      0.012    -94.960      0.000        -1.166    -1.119\n",
      "====================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "529f2aa6450fecc815e6ce897b7b33b0",
     "grade": true,
     "grade_id": "fit_logistic_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(isinstance(model, statsmodels.discrete.discrete_model.Logit), True)\n",
    "assert_equal(isinstance(result, statsmodels.discrete.discrete_model.BinaryResultsWrapper), True)\n",
    "\n",
    "assert_equal(model.exog_names, train_columns)\n",
    "assert_equal(model.endog_names, 'DepDelay_binary')\n",
    "\n",
    "assert_array_equal(model.exog, data[train_columns].values)\n",
    "assert_array_equal(model.endog, data['DepDelay_binary'].values)\n",
    "\n",
    "test_conf_int = result.conf_int()\n",
    "answer_conf_int = pd.DataFrame(\n",
    "    index=train_columns,\n",
    "    data={\n",
    "        0: np.array([\n",
    "            -0.18681953, -0.01247828,  0.18652782,  0.17760447, -0.00675086,\n",
    "            0.07974488, -0.6227236 , -0.06873794,  0.50352299,  0.78551841,\n",
    "            0.06694527,  0.21153022,  0.30383117,  0.17150234,  0.20497387,\n",
    "            -1.166157  ]),\n",
    "        1: np.array([\n",
    "            -0.12794527,  0.04524193,  0.24298324,  0.23413964,  0.05254801,\n",
    "            0.13724129, -0.09649653,  0.04848345,  0.59783265,  0.93824414,\n",
    "            0.11429806,  0.30780938,  0.44591082,  0.20879553,  0.30969833,\n",
    "            -1.11899193])\n",
    "        }\n",
    "    )\n",
    "assert_frame_equal(test_conf_int, answer_conf_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the probability of flights being delayed is higher on Thursdays (`DayOfWeek_4`) and Fridays(`DayOfWeek_5`). In terms of carriers, `HP` an `MQ` airlines are more likely to be delayed than others.\n",
    "\n",
    "Does this result make sense? Let calculate the mean of `DepDelay` for each day of the week. We see that Thursday and Friday have the highest mean values.\n",
    "\n",
    "```python\n",
    ">>> print(local.groupby('DayOfWeek').mean().sort_values(by='DepDelay', ascending=False))\n",
    "```\n",
    "\n",
    "```\n",
    "            DepDelay  DepDelay_binary\n",
    "DayOfWeek                            \n",
    "4          11.419251         0.311135\n",
    "5          11.306297         0.309324\n",
    "7          10.244282         0.288786\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "fa2a3dcfec38d1c78faab170925d71f3",
     "grade": false,
     "grade_id": "print_day_groupby",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            DepDelay  DepDelay_binary\n",
      "DayOfWeek                            \n",
      "4          11.419251         0.311135\n",
      "5          11.306297         0.309324\n",
      "7          10.244282         0.288786\n",
      "3           9.962156         0.270426\n",
      "1           9.336543         0.267238\n",
      "6           9.015426         0.271879\n",
      "2           7.230843         0.237644\n"
     ]
    }
   ],
   "source": [
    "print(local.groupby('DayOfWeek').mean().sort_values(by='DepDelay', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same for `UniqueCarrier`, and HP and DL airline indeed have the highest mean departure delay.\n",
    "\n",
    "```python\n",
    ">>> print(local.groupby('UniqueCarrier').mean().sort_values(by='DepDelay', ascending=False))\n",
    "```\n",
    "\n",
    "```\n",
    "               DayOfWeek   DepDelay  DepDelay_binary\n",
    "UniqueCarrier                                       \n",
    "HP              3.973684  18.245494         0.444845\n",
    "DL              3.972141  11.719453         0.370235\n",
    "UA              3.953615  11.027225         0.291036\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6db243fab957aebc84981ba2c43c50a8",
     "grade": false,
     "grade_id": "print_delay_groupby",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               DayOfWeek   DepDelay  DepDelay_binary\n",
      "UniqueCarrier                                       \n",
      "HP              3.973684  18.245494         0.444845\n",
      "DL              3.972141  11.719453         0.370235\n",
      "UA              3.953615  11.027225         0.291036\n",
      "TW              3.881535  10.183537         0.330645\n",
      "NW              3.827438   9.445194         0.305562\n",
      "CO              3.788118   9.215042         0.251857\n",
      "US              3.922626   9.207263         0.305168\n",
      "MQ              3.937944   9.099671         0.270765\n",
      "AA              3.957042   8.298827         0.253498\n",
      "AS              3.991667   4.791667         0.191667\n"
     ]
    }
   ],
   "source": [
    "print(local.groupby('UniqueCarrier').mean().sort_values(by='DepDelay', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
