{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<DIV ALIGN=CENTER>\n",
    "\n",
    "# Introduction to Logistic Regression\n",
    "## Professor Robert J. Brunner\n",
    "  \n",
    "</DIV>  \n",
    "-----\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In earlier lessons, we have seen how to perform a regression on input\n",
    "data to predict a continuous value. In some cases, however, we wish to\n",
    "predict a categorical value, such as True/False or Yes/No. Traditional\n",
    "regression methods are not optimal for these problems, since they\n",
    "are not continuous values. In this case, we need to employ a special\n",
    "function, known as a [_logit_ function][wlf] that can separate data into two\n",
    "classes. This type of regression is known as [logistic regression][wlr] (since\n",
    "you are using a logit function). \n",
    "\n",
    "In this notebook, we introduce logistic regression and demonstrate how\n",
    "to use logistic regression to predict whether a flight is on time or\n",
    "not. In this notebook, we will specifically use the [logistic regression\n",
    "functionality][sllr] in the scikit learn library. First we will set up\n",
    "this Notebook by importing the airline data that we will use for our\n",
    "Logistic Regression.\n",
    "\n",
    "-----\n",
    "[wlr]: https://en.wikipedia.org/wiki/Logistic_regression\n",
    "[wlf]: https://en.wikipedia.org/wiki/Logit\n",
    "[sllr]: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We do this to ignore several specific Pandas warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# Change this to read a different file, for example\n",
    "# /home/data_scientist/rppdm/data/2001.csv in a local Docker container.\n",
    "#\n",
    "# Note that the JupyterHub server has data from other years in the raw\n",
    "# subdirectory.\n",
    "#\n",
    "#filename = '/home/data_scientist/rppdm/data/2001.csv'\n",
    "filename = '/home/data_scientist/data/2001.csv'\n",
    "\n",
    "# Read select columns for all rows.\n",
    "\n",
    "ucs = (1, 2, 4, 14, 15, 16, 17, 18)\n",
    "cnms = ['Month', 'Day', 'dTime', 'aDelay', 'dDelay', 'Depart', 'Arrive', 'Distance']\n",
    "\n",
    "od = pd.read_csv(filename, header=0, na_values=['NA'], usecols=ucs, names=cnms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Data Transformation\n",
    "\n",
    "Following the discussion in the [Introduction to Machine Learning\n",
    "Pre-Processing][imlp] notebook, we first perform some data\n",
    "pre-processing. To simplify the computations, we will first extract only\n",
    "those flights that depart from O'Hare international airport in Chicago.\n",
    "After this, we will drop any row that has no value in the _departure\n",
    "time_ column, and fill any missing values in the _arrival time_ column\n",
    "with zero.\n",
    "\n",
    "-----\n",
    "\n",
    "[imlp]: ../notebooks/intro2data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldata = od[od['Depart'] == 'ORD']\n",
    "\n",
    "# Drop any row that is missing a departure time\n",
    "#\n",
    "# axis=0 means drop rows\n",
    "# subset=['dTime'] means drop if the departure time is missing\n",
    "# inplace=True means modify the existing DataFrame\n",
    "\n",
    "alldata.dropna(axis=0, subset=['dTime'], inplace=True)\n",
    "\n",
    "# Now replace missing values (which are all in Arrival Delay column)\n",
    "# with 0, note we could use another value, such as the departure delay.\n",
    "\n",
    "alldata.fillna(value=0, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "We next extract columns from this cleaned DataFrame for our logistic\n",
    "regression. For the most flexibility, we extract the hour and minute\n",
    "columns, and convert the arrival airport column to a categorical value.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First create a new DataFrame\n",
    "# For now, simply copy over the columns, but we could\n",
    "# convert them to integers (for number, the number of minutes in the delay)\n",
    "# and change data type to save memory.\n",
    "\n",
    "newdata = alldata[['aDelay', 'dDelay', 'Distance']]\n",
    "\n",
    "# Now copy over the departure and Arrival columns, \n",
    "# but change data type to categoricals. \n",
    "\n",
    "#newdata['Depart'] = alldata['Depart'].astype('category')\n",
    "newdata['Arrive'] = alldata['Arrive'].astype('category')\n",
    "\n",
    "newdata['Month'] = alldata.Month\n",
    "newdata['Day'] = alldata.Day\n",
    "newdata['Hour'] = (alldata.dTime/100.).astype(int)\n",
    "newdata['Min'] = (alldata.dTime - 100*(alldata.dTime/100.).astype(int)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "We now create our categorical column, _arrival late_, that is zero if\n",
    "the flight arrived less than a specific number of minutes after the\n",
    "scheduled arrival time (encoded in `value`), or one if it arrived more\n",
    "than this number of minutes after the scheduled time. We will use this\n",
    "to train our logistic regressor.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add new column for Late Arrival. If arrival delay - departure delay is \n",
    "# greater than value, we consider it a late arrival.\n",
    "\n",
    "value = 5. # Five Minutes\n",
    "newdata['aLate'] = (newdata.aDelay > value).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Logistic Regression\n",
    "\n",
    "We will use the scikit learn library to perform logistic regression. As\n",
    "we have discussed previously, `sklearn` operates on `numpy` arrays.\n",
    "However, we can use the formula interface to construct a `pandas`\n",
    "DataFrame, and extract the columns for use in `sklearn`. To do this, we\n",
    "use the `patsy` library, which supports a formula interface (as we used\n",
    "with the `statsmodel` library. In this simple example, we will compute a\n",
    "logistic regression on the delay, distance, month, day, and hour\n",
    "columns. We also turn the last three columns into category variables (by\n",
    "wrapping them in the `C()` notation). In this case, you should try using\n",
    "only one of these three columns to study the effect of _Month_, _Day_,\n",
    "or _Hour_ on the logistic regression.\n",
    "\n",
    "After we create the `numpy` matrices, we next create a\n",
    "`LogisticRegression` object and use the `fit` method to determine the\n",
    "best possible regression on the entire data. We use the `score` method\n",
    "to quantify how well we can do with this technique, achieving nearly\n",
    "`84%` accuracy.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import patsy as pts \n",
    "\n",
    "y, x = pts.dmatrices('aLate ~ dDelay + Distance + C(Month) + C(Day) + C(Hour)', \n",
    "                     newdata, return_type='dataframe')\n",
    "\n",
    "# y needs to be a 1D array for scikit learn\n",
    "y = np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 83.6%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model = model.fit(x, y)\n",
    "\n",
    "print('Score = {:.1%}'.format(model.score(x, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "We can easily change the regression to use only the _Hour_ categorial\n",
    "column, in addition to the departure delay and distance columns. After\n",
    "computing this regression, we can explore the different dependence of\n",
    "the regression formula on these columns by comparing the fit\n",
    "coefficients as shown below. As one might expect, the coefficients are\n",
    "very small for hours where few, if any, flights depart. On the other\n",
    "hand, the coefficients are large for flights leaving around morning,\n",
    "noon, and early evening.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y, x = pts.dmatrices('aLate ~ dDelay + Distance + C(Hour)', \n",
    "                     newdata, return_type='dataframe')\n",
    "\n",
    "# y needs to be a 1D array for scikit learn\n",
    "y = np.ravel(y)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model = model.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Variable   Coefficient\n",
      "0       Intercept -7.842642e-01\n",
      "1    C(Hour)[T.1]  2.225825e-07\n",
      "2    C(Hour)[T.2]  2.271573e-08\n",
      "3    C(Hour)[T.3]  2.572224e-09\n",
      "4    C(Hour)[T.5]  1.643302e-01\n",
      "5    C(Hour)[T.6] -7.826077e-03\n",
      "6    C(Hour)[T.7]  4.659641e-02\n",
      "7    C(Hour)[T.8]  1.015632e-01\n",
      "8    C(Hour)[T.9] -5.560310e-02\n",
      "9   C(Hour)[T.10] -4.541367e-02\n",
      "10  C(Hour)[T.11] -2.452811e-01\n",
      "11  C(Hour)[T.12]  2.867560e-01\n",
      "12  C(Hour)[T.13]  4.905729e-02\n",
      "13  C(Hour)[T.14] -2.433214e-01\n",
      "14  C(Hour)[T.15]  8.056267e-02\n",
      "15  C(Hour)[T.16] -1.476660e-01\n",
      "16  C(Hour)[T.17]  3.166419e-01\n",
      "17  C(Hour)[T.18] -1.144096e-01\n",
      "18  C(Hour)[T.19] -1.757001e-02\n",
      "19  C(Hour)[T.20] -3.264758e-01\n",
      "20  C(Hour)[T.21] -1.196160e-01\n",
      "21  C(Hour)[T.22] -4.795377e-01\n",
      "22  C(Hour)[T.23] -2.008258e-02\n",
      "23  C(Hour)[T.24]  6.868646e-08\n",
      "24         dDelay  1.440727e-01\n",
      "25       Distance  1.057558e-04\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Variable': x.columns})\n",
    "df['Coefficient'] = np.transpose(model.coef_)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### Training/Testing\n",
    "\n",
    "In the previous examples, we used *all* of the data to fit the regressor\n",
    "and compute an accuracy. In practice that is not a good idea, since we\n",
    "will have little idea how well our regressor will perform on new, unseen\n",
    "data. A better idea is to train on a subset of the data and test this\n",
    "new regressor on unseen _test_ data. We do this below, by splitting our\n",
    "data into a _training_ sample, and a testing sample by using the\n",
    "`train_test_split` method in scikit learn. Specifically in this example,\n",
    "we use 75% of the data for training and 25% of the data for testing (you\n",
    "should change this value and see how the scores change). In this case,\n",
    "our regressor achieves nearly the same score as the full data regressor\n",
    "achieved, indicating that we have a fairly robust predictor.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.833041817077\n",
      "0.854490195187\n",
      "[[49446  2488]\n",
      " [10971 17708]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.82      0.95      0.88     51934\n",
      "        1.0       0.88      0.62      0.72     28679\n",
      "\n",
      "avg / total       0.84      0.83      0.82     80613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Evaluate the model by splitting into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# Fit a new model\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(x_train, y_train)\n",
    "\n",
    "predicted = model2.predict(x_test)\n",
    "probs = model2.predict_proba(x_test)\n",
    "\n",
    "# Generate and display different evaluation metrics\n",
    "print(metrics.accuracy_score(y_test, predicted))\n",
    "print(metrics.roc_auc_score(y_test, probs[:, 1]))\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, predicted))\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "We can also display more traditional measures of the regressor's\n",
    "accuracy. In this case, we can compute and display the mean absolute\n",
    "error, the mean squared error, and the root mean square error.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 0.1670\n",
      "MSE = 0.1670\n",
      "RMSE = 0.4086\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE = {:5.4f}\".format(metrics.mean_absolute_error(y_test, predicted)))\n",
    "print(\"MSE = {:5.4f}\".format(metrics.mean_squared_error(y_test, predicted)))\n",
    "print(\"RMSE = {:5.4f}\".format(np.sqrt(metrics.mean_squared_error(y_test, predicted))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "\n",
    "One last point is that we can obtain an even better understanding of the\n",
    "accuracy of our regression by repeatedly testing how well this approach\n",
    "works with random subsets of the original data. We can do this by using\n",
    "the `cross_validation` functionality in the scikit learn library, as\n",
    "shown below. In this case, we compute the regressor for ten different\n",
    "subsets, and compute the mean score, which demonstrates the power of\n",
    "this approach.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8331576   0.84329839  0.84137567  0.84283322  0.83973206  0.84512327\n",
      "  0.84413087  0.83262002  0.81686515  0.80864657]\n",
      "0.834778284183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# Evaluate the model using 10-fold cross-validation\n",
    "scores = cross_val_score(LogisticRegression(), x, y, scoring='accuracy', cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
