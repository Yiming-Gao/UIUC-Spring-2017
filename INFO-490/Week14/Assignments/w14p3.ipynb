{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 14 Problem 3\n",
    "\n",
    "If you are not using the `Assignments` tab on the course JupyterHub server to read this notebook, read [Activating the assignments tab](https://github.com/lcdm-uiuc/info490-sp17/blob/master/help/act_assign_tab.md).\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_  â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded.\n",
    "-----\n",
    "# Problem 14.3. Spark MLlib\n",
    "In this problem, we will use Spark MLlib to perform a logistic regression on the flight data to determine whether a flight would be delayed or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "eab0bbfdcd6f8bddf9f5918fb957d1ff",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "\n",
    "from nose.tools import (\n",
    "    assert_equal, assert_is_instance,\n",
    "    assert_true, assert_almost_equal\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run Spark in [local mode](http://spark.apache.org/docs/latest/programming-guide.html#local-vs-cluster-modes) from within our Docker container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "16bca5e80ce71a0ed1c738b5d875c273",
     "grade": false,
     "grade_id": "spark_context",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sc = SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use code similar to the RDD code from the [Introduction to Spark](../notebooks/intro2spark.ipynb) notebook to import two columns: `ArrDealy` and `DepDelay`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "fde601ff8bf8f8a411994a977ae6aa64",
     "grade": false,
     "grade_id": "text_file",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "text_file = sc.textFile('/home/data_scientist/data/2001/2001-12.csv')\n",
    "\n",
    "data = (\n",
    "    text_file\n",
    "    .map(lambda line: line.split(\",\"))\n",
    "    # 14: ArrDelay, 15: DepDelay\n",
    "    .map(lambda p: (p[14], p[15]))\n",
    "    .filter(lambda line: 'ArrDelay' not in line)\n",
    "    .filter(lambda line: 'NA' not in line)\n",
    "    .map(lambda p: (int(p[0]), int(p[1])))\n",
    "    )\n",
    "\n",
    "len_data = data.count()\n",
    "assert_equal(len_data, 462433)\n",
    "assert_equal(\n",
    "    data.take(5),\n",
    "    [(27, 24), \n",
    "     (-18, -10), \n",
    "     (-8, -5), \n",
    "     (24, -3), \n",
    "     (8, -5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: to_binary\n",
    "- Write a function that transforms the `ArrDelay` column into binary labels that indicate whether a flight arrived late or not. We define a flight to be delayed if its arrival delay is **15 minutes or more**, the same definition used by the FAA (source: [Wikipedia](https://en.wikipedia.org/wiki/Flight_cancellation_and_delay)).\n",
    "\n",
    "- The `DepDelay` column should remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "d08118a57ba545b17f78159ee5f108e7",
     "grade": false,
     "grade_id": "to_binary_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def to_binary(rdd):\n",
    "    '''\n",
    "    Transforms the \"ArrDelay\" column into binary labels\n",
    "    that indicate whether a flight arrived late (1) or not (0).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rdd: A pyspark.rdd.RDD instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pyspark.rdd.PipelinedRDD instance.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    rdd = rdd.map(lambda x: (int(x[0] >= 15), x[1]))\n",
    "    \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9909571aa4cb46d07e1aa514f62347af",
     "grade": false,
     "grade_id": "to_binary_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 24), (0, -10), (0, -5), (1, -3), (0, -5)]\n"
     ]
    }
   ],
   "source": [
    "binary_labels = to_binary(data)\n",
    "print(binary_labels.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "01e51dc97094a9ea1f0762d357c6c606",
     "grade": true,
     "grade_id": "to_binary_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(binary_labels, pyspark.rdd.PipelinedRDD)\n",
    "assert_equal(binary_labels.count(), len_data)\n",
    "assert_equal(\n",
    "    binary_labels.take(5),\n",
    "    [(1, 24), \n",
    "     (0, -10), \n",
    "     (0, -5), \n",
    "     (1, -3), \n",
    "     (0, -5)])\n",
    "assert_equal(to_binary(sc.parallelize([(15.0, 120.0)])).first(), (1, 120.0))\n",
    "assert_equal(to_binary(sc.parallelize([(14.9, 450.0)])).first(), (0, 450.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: to_labeled_point\n",
    "Our data must be in a Spark specific data structure called [LabeledPoint](https://spark.apache.org/docs/latest/mllib-data-types.html#labeled-point). So: \n",
    "\n",
    "- Write a function that turns a Spark sequence of tuples into a sequence containing LabeledPoint values for each row. \n",
    "- The arrival delay should be the label, and the departure delay should be the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "407bd73ec6a1c03d23d91a65c0d0b6a6",
     "grade": false,
     "grade_id": "to_labeled_point_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def to_labeled_point(rdd):\n",
    "    '''\n",
    "    Transforms a Spark sequence of tuples into\n",
    "    a sequence containing LabeledPoint values for each row.\n",
    "    \n",
    "    The arrival delay is the label.\n",
    "    The departure delay is the feature.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rdd: A pyspark.rdd.RDD instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pyspark.rdd.PipelinedRDD instance.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    rdd = rdd.map(lambda p: LabeledPoint(p[0], [p[1]]))\n",
    "    \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "0ac7b52588396909049e7aff68aa7f1c",
     "grade": false,
     "grade_id": "to_labeled_point_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LabeledPoint(1.0, [24.0]), LabeledPoint(0.0, [-10.0]), LabeledPoint(0.0, [-5.0]), LabeledPoint(1.0, [-3.0]), LabeledPoint(0.0, [-5.0])]\n"
     ]
    }
   ],
   "source": [
    "labeled_point = to_labeled_point(binary_labels)\n",
    "print(labeled_point.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "9c00a3a0b457c913c35c0f4b0f5006a9",
     "grade": true,
     "grade_id": "to_labeled_point_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(labeled_point, pyspark.rdd.PipelinedRDD)\n",
    "assert_equal(labeled_point.count(), len_data)\n",
    "assert_true(all(isinstance(p, LabeledPoint) for p in labeled_point.take(5)))\n",
    "assert_equal([p.label for p in labeled_point.take(5)], [1.0, 0.0, 0.0, 1.0, 0.0])\n",
    "assert_true(all(\n",
    "    isinstance(p.features, pyspark.mllib.linalg.DenseVector)\n",
    "    for p\n",
    "    in labeled_point.take(5)\n",
    "    ))\n",
    "assert_equal(\n",
    "    [p.label for p in labeled_point.take(5)],\n",
    "    [1.0,\n",
    "     0.0,\n",
    "     0.0,\n",
    "     1.0,\n",
    "     0.0]\n",
    "    )\n",
    "assert_equal(\n",
    "    [p.features.values.tolist() for p in labeled_point.take(5)],\n",
    "    [[24.0],\n",
    "     [-10.0],\n",
    "     [-5.0],\n",
    "     [-3.0],\n",
    "     [-5.0]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: fit_and_predict\n",
    "- Use [LogisticRegressionWithLBFGS](http://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.classification.LogisticRegressionWithLBFGS) to train a [logistic regression](http://spark.apache.org/docs/latest/mllib-linear-methods.html#logistic-regression) model. \n",
    "- Use 10 iterations. Use default parameters for all other parameters other than `iterations`.\n",
    "- Use the resulting logistic regression model to make predictions on the entire data, and return an RDD of (label, prediction) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "19693dcb87436d0cb28822667bac09b5",
     "grade": false,
     "grade_id": "fit_and_predict_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_and_predict(rdd):\n",
    "    '''\n",
    "    Fits a logistic regression model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rdd: A pyspark.rdd.RDD instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    An RDD of (label, prediction) pairs.\n",
    "    '''\n",
    "    \n",
    "    # logistic regression\n",
    "    model = LogisticRegressionWithLBFGS.train(rdd, iterations = 10)\n",
    "    \n",
    "    rdd = rdd.map(lambda lp: (lp.label, float(model.predict(lp.features))))\n",
    "    \n",
    "    return rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "feefcd17f0a85b8556d765a5556a6749",
     "grade": false,
     "grade_id": "fit_and_predict_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1.0, 1.0), (0.0, 0.0), (0.0, 0.0), (1.0, 0.0), (0.0, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "labels_and_preds = fit_and_predict(labeled_point)\n",
    "print(labels_and_preds.take(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "7476d4f44986ffcb2cb4f6f5c34f8d32",
     "grade": true,
     "grade_id": "fit_and_predict_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(labels_and_preds, pyspark.rdd.PipelinedRDD)\n",
    "assert_equal(labels_and_preds.count(), len_data)\n",
    "assert_equal(\n",
    "    labels_and_preds.take(5),\n",
    "    [(1.0, 1.0),\n",
    "     (0.0, 0.0),\n",
    "     (0.0, 0.0),\n",
    "     (1.0, 0.0),\n",
    "     (0.0, 0.0)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: get_accuracy\n",
    "- Write a function that computes the accuracy from a Spark sequence of (label, prediction) pairs.\n",
    "- Accuracy is defined as the total number of correctly classified instances out of the total number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "cf32b427eb7b08edc8e24f0bb2163246",
     "grade": false,
     "grade_id": "get_accuracy_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(rdd):\n",
    "    '''\n",
    "    Computes accuracy.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rdd: A pyspark.rdd.RDD instance.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A float.\n",
    "    '''\n",
    "    \n",
    "    # number of rows\n",
    "    nrows = rdd.count()\n",
    "    \n",
    "    # number of correct predicted pairs\n",
    "    ncount = rdd.filter(lambda x: x[0] == x[1]).count()\n",
    "    \n",
    "    # accuracy\n",
    "    accuracy = ncount / nrows\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "ca760ae468805a16e6c3cef0aa0a6d32",
     "grade": false,
     "grade_id": "get_accuracy_run",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7193388015128678\n"
     ]
    }
   ],
   "source": [
    "accuracy = get_accuracy(labels_and_preds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "f59a6890f2ac4d12c7e68c46d8af2d9e",
     "grade": true,
     "grade_id": "get_accuracy_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(accuracy, float)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(0.0, 1.0), (1.0, 0.0)])), 0.0)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(0.0, 1.0), (0.0, 0.0)])), 0.5)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(0.0, 0.0), (1.0, 0.0)])), 0.5)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(0.0, 0.0), (1.0, 1.0)])), 1.0)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(1.0, 0.0), (0.0, 1.0), (0.0, 1.0)])), 0.0)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(1.0, 1.0), (0.0, 1.0), (0.0, 1.0)])), 1/3)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(1.0, 1.0), (0.0, 0.0), (0.0, 1.0)])), 2/3)\n",
    "assert_almost_equal(get_accuracy(sc.parallelize([(1.0, 1.0), (0.0, 0.0), (1.0, 1.0)])), 1.0)\n",
    "assert_almost_equal(accuracy, 0.7193388015128678)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "We must stop the SparkContext in order to release the spark resources before existing this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "ec8c059e7ca934a0d1fb3342fc042680",
     "grade": false,
     "grade_id": "sc_stop",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
