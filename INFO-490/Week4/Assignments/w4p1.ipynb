{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b5f48fc21d44db8123f1f2bac25a4e3a",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Week 4 Problem 1\n",
    "\n",
    "If you are not using the `Assignments` tab on the course JupyterHub server to read this notebook, read [Activating the assignments tab](https://github.com/lcdm-uiuc/info490-sp17/blob/master/help/act_assign_tab.md).\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `YOUR CODE HERE`. Do **not** write your answer in anywhere else other than where it says `YOUR CODE HERE`. Anything you write anywhere else will be removed or overwritten by the autograder.\n",
    "\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to menubar, select _Kernel_, and restart the kernel and run all cells (_Restart & Run all_).\n",
    "\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "\n",
    "4. Make sure that you save your work (in the menubar, select _File_  â†’ _Save and CheckPoint_)\n",
    "\n",
    "5. You are allowed to submit an assignment multiple times, but only the most recent submission will be graded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "In this problem, we will use the Decision Trees algorithm to see if we can use machine learning techniques to predict departure delays at the O'Hare airport (ORD).\n",
    "\n",
    "A bit of introduction before we begin. You will see that this problem is not really about decision trees but data preparation. However, it is what practical data science is really about; the actual machine learning, especially with packages like scikit-learn, is a line of `fit` and `predict`. The rest is data wrangling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "be7953bdb303181791e933655af4366a",
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nose.tools import assert_equal, assert_is_not, assert_is_instance\n",
    "from numpy.testing import assert_array_equal, assert_array_almost_equal, assert_almost_equal\n",
    "from pandas.util.testing import assert_frame_equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you want to include weather as training features. `2001.csv` doesn't have weather information, so we have to gather the data ourselves. There are various weather APIs available, one of which is [Weather Underground](http://www.wunderground.com/). Their terms of service says I have to display their logo, so here it is:\n",
    "\n",
    "![](http://www.wunderground.com/logos/images/wundergroundLogo_4c.jpg)\n",
    "\n",
    "After you sign up for an account and generate an API token, you can issue HTTP requests such as:\n",
    "\n",
    "```\n",
    "http://api.wunderground.com/api/<token number>/history_20010101/conditions/q/KORD.json\n",
    "```\n",
    "\n",
    "The above example will return a JSON with historical weather information on January 1, 2001 (20010101) at O'Hare (KORD). To save you the trouble of dealing with the Weather Underground API, I saved the JSON responses as `.json` files in `/home/data_scientist/data/weather`.\n",
    "\n",
    "```shell\n",
    "$ ls /home/data_scientist/data/weather | head\n",
    "```\n",
    "\n",
    "```\n",
    "weather_kord_2001_0101.json\n",
    "weather_kord_2001_0102.json\n",
    "weather_kord_2001_0103.json\n",
    "weather_kord_2001_0104.json\n",
    "weather_kord_2001_0105.json\n",
    "weather_kord_2001_0106.json\n",
    "weather_kord_2001_0107.json\n",
    "weather_kord_2001_0108.json\n",
    "weather_kord_2001_0109.json\n",
    "weather_kord_2001_0110.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7be4c8dca7a1b7d2eb55863bf752288f",
     "grade": false,
     "grade_id": "ls_weather",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_visi.csv\r\n",
      "weather_kord_2001_0101.json\r\n",
      "weather_kord_2001_0102.json\r\n",
      "weather_kord_2001_0103.json\r\n",
      "weather_kord_2001_0104.json\r\n",
      "weather_kord_2001_0105.json\r\n",
      "weather_kord_2001_0106.json\r\n",
      "weather_kord_2001_0107.json\r\n",
      "weather_kord_2001_0108.json\r\n",
      "weather_kord_2001_0109.json\r\n",
      "ls: write error: Broken pipe\r\n"
     ]
    }
   ],
   "source": [
    "!ls /home/data_scientist/data/weather | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each file contains exactly the same response you would get from the Weather Underground API, because I simply dumped the JSON responses to files. Here is the full code that generated these files:\n",
    "\n",
    "```python\n",
    "def get_2001_json(date, year=2001):\n",
    "    url = 'http://api.wunderground.com/api/e693d410bdf457e2/history_{0}{1}/conditions/q/KORD.json'.format(year, date)\n",
    "    resp = requests.get(url)\n",
    "    resp_json = resp.json()\n",
    "    return resp_json\n",
    "\n",
    "def save_2001_json(date, dir_name='data', filename='weather_kord_2001_{}.json'):\n",
    "    data = get_2001_json(date)\n",
    "    path = os.path.join(dir_name, filename.format(date))\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "dates = ['{0:0>2}{1:0>2}'.format(m, d) for m in [1, 3, 5, 7, 8, 10, 12] for d in range(1, 32)]\n",
    "dates.extend(['{0:0>2}{1:0>2}'.format(m, d) for m in [4, 6, 9, 11] for d in range(1, 31)])\n",
    "dates.extend(['02{0:0>2}'.format(d) for d in range(1, 29)])\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "for d in dates:\n",
    "    save_2001_json(d)\n",
    "    time.sleep(6) # free plan limit: 10 calls/min\n",
    "```\n",
    "\n",
    "Do not run this code to generate these files. We will use the files in `/home/data_scientist/data/weather` instead.\n",
    "\n",
    "## Load JSON files\n",
    "\n",
    "- Write a function named `from_json_to_dict()` that takes a string in the format `MMDD` (M = Month, D = Day of month) and returns a dictoinary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "5e657fd6a633cb0d91856d986a629f36",
     "grade": false,
     "grade_id": "from_json_to_dict_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def from_json_to_dict(date, path='/home/data_scientist/data/weather/', prefix='weather_kord_2001_'):\n",
    "    '''\n",
    "    Takes a string in the format MMDD where M = month, D = day of month.\n",
    "    Read a json file at \"path\" + \"prefix\" + \"date\".\n",
    "    Returns the JSON dictionary.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    date: A string.\n",
    "    \n",
    "    Optional\n",
    "    --------\n",
    "    path: A string.\n",
    "    prefix: A string.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A dict.\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    # define file name\n",
    "    name = path + prefix + date + \".json\"\n",
    "    \n",
    "    # \"r\": the file will only be read\n",
    "    with open(name, 'r') as myfile:\n",
    "        string_of_JSON = myfile.readline()\n",
    "    \n",
    "    data = json.loads(string_of_JSON)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests for `from_json_to_dict()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2933eb735de035b64ccc397bcce9a472",
     "grade": true,
     "grade_id": "from_json_to_dict_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_0101_dict = from_json_to_dict('0101')\n",
    "assert_is_instance(test_0101_dict, dict)\n",
    "assert_equal('history' in test_0101_dict, True)\n",
    "assert_equal('observations' in test_0101_dict['history'], True)\n",
    "assert_is_instance(test_0101_dict['history']['observations'], list)\n",
    "\n",
    "test_0103_dict = from_json_to_dict('0103')\n",
    "assert_is_instance(test_0103_dict, dict)\n",
    "assert_equal('history' in test_0103_dict, True)\n",
    "assert_equal('observations' in test_0103_dict['history'], True)\n",
    "assert_is_instance(test_0103_dict['history']['observations'], list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse time and visibility from JSON\n",
    "\n",
    "- Write a function named `from_dict_to_visibility()` that takes a dictionary and returns a tuple of `(Month, Day, Hour, Minute, Visibility)`.\n",
    "\n",
    "We covered the json format in the previous course, so you know how to do this. Let's say you created a dictionary called `data` by reading the json file `weather_kord_2001_0101.json`.\n",
    "\n",
    "```python\n",
    ">>> data = from_json_to_dict('0101')\n",
    ">>> print(data.keys()\n",
    "```\n",
    "\n",
    "```\n",
    "dict_keys(['response', 'current_observation', 'history'])\n",
    "```\n",
    "\n",
    "You can peek into `response` and `current_observation` but they are not important for our purposes, so we look at `history`:\n",
    "\n",
    "```python\n",
    ">>> print(data['history'].keys())\n",
    "```\n",
    "\n",
    "```\n",
    "dict_keys(['observations', 'date', 'dailysummary', 'utcdate'])\n",
    "```\n",
    "\n",
    "Here, `observations` is a list.\n",
    "\n",
    "```python\n",
    ">>> print(type(data['history']['observations']))\n",
    "```\n",
    "\n",
    "```\n",
    "<class 'list'>\n",
    "```\n",
    "\n",
    "The first element looks like as follows:\n",
    "\n",
    "```python\n",
    ">>> from pprint import pprint\n",
    ">>> pprint(data['history']['observations'][0])\n",
    "```\n",
    "\n",
    "```\n",
    "{'conds': 'Overcast',\n",
    " 'date': {'hour': '00',\n",
    "          'mday': '01',\n",
    "          'min': '56',\n",
    "          'mon': '01',\n",
    "          'pretty': '12:56 AM CST on January 01, 2001',\n",
    "          'tzname': 'America/Chicago',\n",
    "          'year': '2001'},\n",
    " 'dewpti': '10.9',\n",
    " 'dewptm': '-11.7',\n",
    " 'fog': '0',\n",
    " 'hail': '0',\n",
    " 'heatindexi': '-9999',\n",
    " 'heatindexm': '-9999',\n",
    " 'hum': '92',\n",
    " 'icon': 'cloudy',\n",
    " 'metar': 'METAR KORD 010656Z 36004KT 9SM BKN055 OVC095 M11/M12 A3034 RMK '\n",
    "          'AO2 SLP285 T11061117 $',\n",
    " 'precipi': '-9999.00',\n",
    " 'precipm': '-9999.00',\n",
    " 'pressurei': '30.38',\n",
    " 'pressurem': '1028.5',\n",
    " 'rain': '0',\n",
    " 'snow': '0',\n",
    " 'tempi': '12.9',\n",
    " 'tempm': '-10.6',\n",
    " 'thunder': '0',\n",
    " 'tornado': '0',\n",
    " 'utcdate': {'hour': '06',\n",
    "             'mday': '01',\n",
    "             'min': '56',\n",
    "             'mon': '01',\n",
    "             'pretty': '6:56 AM GMT on January 01, 2001',\n",
    "             'tzname': 'UTC',\n",
    "             'year': '2001'},\n",
    " 'visi': '9.0',\n",
    " 'vism': '14.5',\n",
    " 'wdird': '360',\n",
    " 'wdire': 'North',\n",
    " 'wgusti': '-9999.0',\n",
    " 'wgustm': '-9999.0',\n",
    " 'windchilli': '5.2',\n",
    " 'windchillm': '-14.9',\n",
    " 'wspdi': '4.6',\n",
    " 'wspdm': '7.4'}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "84abbe38d19c2d8c80851522efb445d0",
     "grade": false,
     "grade_id": "from_dict_to_visibility",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def from_dict_to_visibility(json_data):\n",
    "    '''\n",
    "    Takes a dictionary and returns a tuple of (Month, Day, Hour, Minute, Visibility).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    json_data: A dict.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 5-tuple (str, str, str, str, str)\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    mydata = json_data['history']['observations']\n",
    "    result0 = lambda x: (x['date']['mon'], x['date']['mday'], x['date']['hour'], x['date']['min'], x['visi'])\n",
    "    \n",
    "    result = list(map(result0, mydata))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests for `from_dict_to_visibility()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "15c472222e1cc908f3df1b502952cf0f",
     "grade": true,
     "grade_id": "from_dict_to_visibility_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "test_0101_visi = from_dict_to_visibility(test_0101_dict)\n",
    "assert_is_instance(test_0101_visi, list)\n",
    "assert_equal(len(test_0101_visi), 24)\n",
    "for item in test_0101_visi:\n",
    "    assert_is_instance(item, tuple)\n",
    "    assert_equal(len(item), 5) # month, day, hour, minute, visibility\n",
    "    assert_equal(item[0], '01')\n",
    "    assert_equal(item[1], '01')\n",
    "    \n",
    "test_0103_visi = from_dict_to_visibility(test_0103_dict)\n",
    "assert_is_instance(test_0103_visi, list)\n",
    "assert_equal(len(test_0103_visi), 34) # some days have more than one measurement per hour\n",
    "for item in test_0103_visi:\n",
    "    assert_is_instance(item, tuple)\n",
    "    assert_equal(len(item), 5)\n",
    "    assert_equal(item[0], '01')\n",
    "    assert_equal(item[1], '03')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all 365 files\n",
    "\n",
    "We will use the functions `from_json_to_dict()` and `from_dict_to_visibility()` (in a loop) for all 365 days of the year. Let's first generate a list of dates in sequential order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "3ac5e7f935647102d8e5853a94cbe927",
     "grade": false,
     "grade_id": "dates",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first five elements are ['0101', '0102', '0103', '0104', '0105']\n",
      "The last five elements are ['1227', '1228', '1229', '1230', '1231']\n"
     ]
    }
   ],
   "source": [
    "dates = ['{0:0>2}{1:0>2}'.format(m, d + 1) for m in [1, 3, 5, 7, 8, 10, 12] for d in range(31)]\n",
    "dates.extend(['{0:0>2}{1:0>2}'.format(m, d + 1) for m in [4, 6, 9, 11] for d in range(30)])\n",
    "dates.extend(['02{0:0>2}'.format(d + 1) for d in range(28)])\n",
    "dates.sort()\n",
    "\n",
    "assert_equal(len(dates), 365)\n",
    "\n",
    "print(\"The first five elements are {}\".format(dates[:5]))\n",
    "print(\"The last five elements are {}\".format(dates[-5:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function named `collect_365_days()` that takes a list of strings, iterates through the list, and uses `from_json_to_dict()` and `from_dict_to_visibility()` to return a list of 5-tuples `(month, day, hour, minute, visibility)`.\n",
    "\n",
    "Here's the output you should get:\n",
    "\n",
    "```python\n",
    ">>> visibilities = collect_365_days(dates)\n",
    ">>> print(\"The length of visibilities is {}.\".format(len(visibilities)))\n",
    ">>> print(\"The first five elements of visibilities are {}\".format(visibilities[:5]))\n",
    "```\n",
    "\n",
    "```\n",
    "The length of visibilities is 10159.\n",
    "The first five elements of visibilities are [('01', '01', '00', '56', '9.0'), ('01', '01', '01', '56', '7.0'), ('01', '01', '02', '56', '10.0'), ('01', '01', '03', '56', '10.0'), ('01', '01', '04', '56', '9.0')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5675f2613fb79691cff302cd7aa1f2f4",
     "grade": false,
     "grade_id": "collect_365_days_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def collect_365_days(dates):\n",
    "    '''\n",
    "    Uses from_json_to_dict() and from_dict_to_visiblility() to\n",
    "    generate a list of tuples of the form\n",
    "    (Month, Day, Hour, Minute, Visibility)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dates: A list of strings \"MMDD\"\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A list of 5-tuples (str, str, str, str, str)\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    import functools\n",
    "    \n",
    "    convert_fun = lambda x: from_dict_to_visibility(from_json_to_dict(x))\n",
    "    visibilities = list(map(convert_fun, dates))\n",
    "    visibilities = functools.reduce(lambda x, y: x + y, visibilities) \n",
    "        \n",
    "    return visibilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "2183844ca1c40754094823c1c3bb385f",
     "grade": false,
     "grade_id": "collect_365_days_print",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of visibilities is 10159.\n",
      "The first five elements of visibilities are [('01', '01', '00', '56', '9.0'), ('01', '01', '01', '56', '7.0'), ('01', '01', '02', '56', '10.0'), ('01', '01', '03', '56', '10.0'), ('01', '01', '04', '56', '9.0')]\n"
     ]
    }
   ],
   "source": [
    "visibilities = collect_365_days(dates)\n",
    "\n",
    "print(\"The length of visibilities is {}.\".format(len(visibilities)))\n",
    "print(\"The first five elements of visibilities are {}\".format(visibilities[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "341093cce86228696efbce84b46570ca",
     "grade": true,
     "grade_id": "collect_365_days_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(visibilities, list)\n",
    "assert_equal(len(visibilities), 10159)\n",
    "assert_equal(visibilities[:5],\n",
    "    [('01', '01', '00', '56', '9.0'),\n",
    "     ('01', '01', '01', '56', '7.0'),\n",
    "     ('01', '01', '02', '56', '10.0'),\n",
    "     ('01', '01', '03', '56', '10.0'),\n",
    "     ('01', '01', '04', '56', '9.0')]\n",
    "    )\n",
    "assert_equal(visibilities[-5:],\n",
    "    [('12', '31', '19', '56', '10.0'),\n",
    "     ('12', '31', '20', '56', '10.0'),\n",
    "     ('12', '31', '21', '56', '10.0'),\n",
    "     ('12', '31', '22', '56', '10.0'),\n",
    "     ('12', '31', '23', '56', '10.0')]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will combine the weather data with our flights data. We import the following columns of `2001.csv`:\n",
    "\n",
    "- Column 1: Month, 1-12\n",
    "- Column 2: DayofMonth, 1-31\n",
    "- Column 5: CRSDepTime, scheduled departure time (local, hhmm)\n",
    "- Column 8: UniqueCarrier, unique carrier code\n",
    "- Column 15: DepDelay, departure delay, in minutes\n",
    "- Column 16: Origin, origin IATA airport code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "703c8370875ed9945943d19e209df99c",
     "grade": false,
     "grade_id": "read_csv",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    '/home/data_scientist/data/2001.csv',\n",
    "    encoding='latin-1',\n",
    "    usecols=(1, 2, 5, 8, 15, 16)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use only AA flights that departed from ORD (American Airlines is the largest airline using the O'Hare airport). We define a flight to be delayed if its departure delay is 15 minutes or more, the same definition used by the FAA (source: [Wikipedia](https://en.wikipedia.org/wiki/Flight_cancellation_and_delay))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "511e7829f71cc3c0ab28c3bcaaf60ab6",
     "grade": false,
     "grade_id": "local",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "local = df[(df['Origin'] == 'ORD') & (df['UniqueCarrier'] == 'AA')]\n",
    "local = local.drop(['UniqueCarrier', 'Origin'], axis=1) # we don't need the Month and Origin columns anymore.\n",
    "local['Delayed'] = (local['DepDelay'] > 15).astype(np.int) # 1 if a flight was delayed, 0 if not.\n",
    "local = local.drop('DepDelay', axis=1).dropna() # we don't need the DepDelay column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the first few columns and see what we'll be working with.\n",
    "\n",
    "```python\n",
    ">>> print(local.head(5))\n",
    "```\n",
    "\n",
    "```\n",
    "      Month  DayofMonth  CRSDepTime  Delayed\n",
    "        Month  DayofMonth  CRSDepTime  Delayed\n",
    "398444      1           1        1905        1\n",
    "398445      1           2        1905        1\n",
    "398446      1           3        1905        1\n",
    "398447      1           4        1905        0\n",
    "398448      1           5        1905        1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a21dce3e8525d5c0130ef5fcc3f26831",
     "grade": false,
     "grade_id": "print_local_head",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Month  DayofMonth  CRSDepTime  Delayed\n",
      "398444      1           1        1905        1\n",
      "398445      1           2        1905        1\n",
      "398446      1           3        1905        1\n",
      "398447      1           4        1905        0\n",
      "398448      1           5        1905        1\n"
     ]
    }
   ],
   "source": [
    "print(local.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert strings to numbers\n",
    "\n",
    "Now we want to match the `Month` and `DayofMonth` columns in `local` with the corresponding entries in `visibilities` and find the time in `visibilities` that is closes to the `CRSDepTime`. What would be the best way to about matching the times?\n",
    "\n",
    "Rahter than comparing three columns, I think it's better to combine the three numbers into one long number and compare just one column. Recall that we had a tuple of strings, while the data types in `local` is integer.\n",
    "\n",
    "```python\n",
    ">>> print(local.CRSDepTime.dtype)\n",
    "```\n",
    "\n",
    "```\n",
    "int64\n",
    "```\n",
    "\n",
    "So let's convert the strings into integers in the form `mmddHHMM`, where `m` is month, `d` is day of month, `H` is hour, and `M` is minute. Let's create a data frame from tuple while we are at it so our function can do:\n",
    "\n",
    "```python\n",
    ">>> print(visibilities[:3])\n",
    "```\n",
    "\n",
    "```\n",
    "[('01', '01', '00', '56', '9.0'), ('01', '01', '01', '56', '7.0'), ('01', '01', '02', '56', '10.0')]\n",
    "```\n",
    "\n",
    "```python\n",
    ">>> time_visi = from_string_to_numbers(visibilities)\n",
    ">>> print(time_visi.head(3))\n",
    "```\n",
    "\n",
    "```\n",
    "      Time  Visibility\n",
    "0  1010056           9\n",
    "1  1010156           7\n",
    "2  1010256          10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "e24c52193b66bdd87093fc6061786092",
     "grade": false,
     "grade_id": "from_string_to_numbers_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def from_string_to_numbers(visibilities):\n",
    "    '''\n",
    "    Takes a list of 5-tuples of strings.\n",
    "    Convert the strings into integers in the form `mmddHHMM`,\n",
    "    where `m` is month, `d` is day of month, `H` is hour, and `M` is minute.\n",
    "    Returns a pandas.DataFrame with two columns \"Time\" and \"Visibility\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    visibilities: A list of 5-tuple of strings.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pandas.DataFrame\n",
    "    '''\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    list_time = list(map(lambda x: int(x[0] + x[1] + x[2] + x[3]), visibilities))\n",
    "    list_visibility = list(map(lambda x: float(x[4]), visibilities))\n",
    "    \n",
    "    # create a pandas DataFrame\n",
    "    result = pd.DataFrame({\n",
    "    'Time': list_time, 'Visibility': list_visibility\n",
    "    })\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "9ce89cf52370351b87e8683f66438815",
     "grade": false,
     "grade_id": "time_visi",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Time  Visibility\n",
      "0  1010056         9.0\n",
      "1  1010156         7.0\n",
      "2  1010256        10.0\n"
     ]
    }
   ],
   "source": [
    "time_visi = from_string_to_numbers(visibilities)\n",
    "print(time_visi.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "99c23128a688746e56ed01d33466acc8",
     "grade": true,
     "grade_id": "from_string_to_numbers_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "visi0 = [\n",
    "    ('01', '01', '06', '00', '1.0'),\n",
    "    ('02', '31', '08', '00', '2.0'),\n",
    "    ('10', '05', '07', '00', '3.0'),\n",
    "    ('12', '29', '09', '00', '4.0'),\n",
    "    ('09', '30', '23', '00', '5.0'),\n",
    "    ('07', '04', '12', '00', '6.0'),\n",
    "    ('05', '12', '15', '00', '7.0'),\n",
    "    ('11', '11', '18', '00', '8.0')\n",
    "]\n",
    "\n",
    "visi_answer = pd.DataFrame({\n",
    "    'Time': [1010600, 2310800, 10050700, 12290900,\n",
    "             9302300, 7041200, 5121500, 11111800],\n",
    "    'Visibility': [1., 2., 3., 4., 5., 6., 7., 8.]\n",
    "    })\n",
    "\n",
    "assert_frame_equal(from_string_to_numbers(visi0), visi_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Time column\n",
    "\n",
    "- Do the same for the `local` data frame. Put the result into a column named `Time` so we have\n",
    "\n",
    "```python\n",
    ">>> time_delayed = combine_time(local)\n",
    ">>> print(time_delayed.head())\n",
    "```\n",
    "\n",
    "```\n",
    "        Month  DayofMonth  CRSDepTime  Delayed     Time\n",
    "398444      1           1        1905        1  1011905\n",
    "398445      1           2        1905        1  1021905\n",
    "398446      1           3        1905        1  1031905\n",
    "398447      1           4        1905        0  1041905\n",
    "398448      1           5        1905        1  1051905\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "33d89e6cee0af2c62d42aa05817c4428",
     "grade": false,
     "grade_id": "combine_time_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def combine_time(df):\n",
    "    '''\n",
    "    Combines \"Month\", \"DayofMonth\", and \"CRSDepTime\" in the form mmddHHMM.\n",
    "    Creates a new column named \"Time\".\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A pandas.DataFrame\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A pandas.DataFrame\n",
    "    '''\n",
    "    # make a deep copy\n",
    "    result = df.copy()\n",
    "    \n",
    "    result['Time'] = result['Month'] * 1000000 + result['DayofMonth'] * 10000 + result['CRSDepTime']\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "875f79bbc91909037f034570097a0e89",
     "grade": false,
     "grade_id": "time_delayed",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Month  DayofMonth  CRSDepTime  Delayed     Time\n",
      "398444      1           1        1905        1  1011905\n",
      "398445      1           2        1905        1  1021905\n",
      "398446      1           3        1905        1  1031905\n",
      "398447      1           4        1905        0  1041905\n",
      "398448      1           5        1905        1  1051905\n"
     ]
    }
   ],
   "source": [
    "time_delayed = combine_time(local)\n",
    "print(time_delayed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "b7580bf74f56cd2011935a03a1346a18",
     "grade": true,
     "grade_id": "combine_time_test",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "df0 = pd.DataFrame({\n",
    "    'Month':      [  1,   2,  10,   12,   9,     7,    5,   11],\n",
    "    'DayofMonth': [  1,  31,   5,   29,  30,     4,   12,   11],\n",
    "    'CRSDepTime': [600, 800, 700,  900, 2300, 1200, 1500, 1800]\n",
    "    })\n",
    "\n",
    "df_answer = df0.join(pd.DataFrame({\n",
    "    'Time': [1010600, 2310800, 10050700, 12290900, 9302300, 7041200, 5121500, 11111800]\n",
    "    }))\n",
    "\n",
    "assert_is_not(combine_time(df0), df0)\n",
    "assert_frame_equal(combine_time(df0), df_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find the time closest to the departure time. The following code cell will take a few minutes because we are using `iterrows()`, which is essentially a `for` loop. When you are doing numerical operations with big data in Python, you should avoid for loops as much as possible, and this is why. It's slow. Maybe there's a clever way to do this in a vectorized way, but I couldn't figure it out.\n",
    "\n",
    "You don't have to write the `match_visibility()` function, but you should understand what it's doing.\n",
    "\n",
    "```python\n",
    ">>> local_visi = match_visibility(time_delayed, time_visi)\n",
    ">>> print(local_visi.head())\n",
    "```\n",
    "\n",
    "```\n",
    "        Month  DayofMonth  CRSDepTime  Delayed     Time  Visibility\n",
    "398444      1           1        1905        1  1011905          10\n",
    "398445      1           2        1905        1  1021905           9\n",
    "398446      1           3        1905        1  1031905           5\n",
    "398447      1           4        1905        0  1041905           7\n",
    "398448      1           5        1905        1  1051905          10\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a4a0f770f5cb52ee5478519576d2288b",
     "grade": false,
     "grade_id": "match_visibility",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def match_visibility(df_delayed, df_visibility, inplace=False):\n",
    "    \n",
    "    if not inplace:\n",
    "        # we don't want to change the original data frame\n",
    "        result = df_delayed.copy()\n",
    "    \n",
    "    for idx, row in result.iterrows():\n",
    "        # find the row where the difference between the two times is minimum\n",
    "        matched = (row['Time'] - df_visibility['Time']).idxmin()\n",
    "        \n",
    "        # used the index we found to extract the visibility and insert it into the result\n",
    "        result.loc[idx, 'Visibility'] = df_visibility.loc[matched, 'Visibility']\n",
    "        \n",
    "    return result\n",
    "\n",
    "local_visi = match_visibility(time_delayed, time_visi)\n",
    "\n",
    "print(local_visi.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will split the data set into training and test sets. We will train on two columns, `CRSDepTime` and `Visibility`, so let's drop those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6d589b18fa6e1611cd7a7ccb1920cd7f",
     "grade": false,
     "grade_id": "local_visi",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "local_visi = local_visi.drop(['Month', 'DayofMonth', 'Time'], axis=1)\n",
    "print(local_visi.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split\n",
    "\n",
    "This function is the same function from [Problem 3.1](https://github.com/lcdm-uiuc/info490-sp17/blob/master/Week3/assignments/w3p1.ipynb). You can copy-paste your answer. I'll try not to make you write this again in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "67eae4d370b88fd64557d4903f4e9631",
     "grade": false,
     "grade_id": "split_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def split(df, test_column, test_size, random_state):\n",
    "    '''\n",
    "    Uses sklearn.train_test_split to split \"df\" into a testing set and a test set.\n",
    "    The \"test_columns\" lists the column that we are trying to predict.\n",
    "    All columns in \"df\" except \"test_columns\" will be used for training.\n",
    "    The \"test_size\" should be between 0.0 and 1.0 and represents the proportion of the\n",
    "    dataset to include in the test split.\n",
    "    The \"random_state\" parameter is used in sklearn.train_test_split.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: A pandas.DataFrame\n",
    "    test_columns: A list of strings\n",
    "    test_size: A float\n",
    "    random_state: A numpy.random.RandomState instance\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A 4-tuple of pandas.DataFrames\n",
    "    '''\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # drop test columns\n",
    "    X = pd.DataFrame(data = df.drop(test_column, 1))\n",
    "    Y = pd.DataFrame(data = df, columns = test_column)\n",
    "    \n",
    "    # Cross-validation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = test_size,\n",
    "                                                       random_state = random_state)\n",
    "\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split `local_visi` into 80:20 training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6284f66d2068bcb0908580564810c9f0",
     "grade": false,
     "grade_id": "split_run_test",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split(\n",
    "    df=local_visi,\n",
    "    test_column=['Delayed'],\n",
    "    test_size=0.2,\n",
    "    random_state=check_random_state(0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code cell, we test if the returned DataFrames have the correct columns and lengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Decision Trees model\n",
    "\n",
    "- Write a function named `fit_and_predict()` that trains a **Decision Trees** model. Use default parameters. Don't forget that we have to pass an instance of check_random_state() to the train_test_split() function for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "014a9e715d16a25f0e9ba38558d1089b",
     "grade": false,
     "grade_id": "fit_and_predict_answer",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def fit_and_predict(X_train, y_train, X_test, random_state):\n",
    "    '''\n",
    "    Fits Decision Trees.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: A pandas.DataFrame. Training attributes.\n",
    "    y: A pandas.DataFrame. Truth labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A numpy array.\n",
    "    '''\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    dtc = tree.DecisionTreeClassifier(random_state = random_state)\n",
    "    dtc.fit(X_train, y_train)\n",
    "\n",
    "    prediction = dtc.predict(X_test)\n",
    "\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a166bceb72bfea7d0a0f45bdacf3b201",
     "grade": false,
     "grade_id": "y_pred",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.82.\n"
     ]
    }
   ],
   "source": [
    "y_pred = fit_and_predict(X_train, y_train, X_test, random_state=check_random_state(0))\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('The accuracy score is {:0.2f}.'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "7582f8def41a72d4bafffbad2917420b",
     "grade": true,
     "grade_id": "fit_and_predict_test",
     "locked": true,
     "points": 10,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_is_instance(y_pred, np.ndarray)\n",
    "assert_equal(len(y_pred), len(y_test))\n",
    "assert_almost_equal(accuracy, 0.819190107608)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
